{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_validate, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Reshape, MaxPool3D, Bidirectional, ConvLSTM2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import GRU\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Dropout\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "import pymongo\n",
    "import random\n",
    "import string\n",
    "import fasttext\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tag import pos_tag\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from textblob import TextBlob\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "HOME = os.environ['LIMA_HOME']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text: str) -> list:\n",
    "    \"\"\"\n",
    "    clean text with tokenization; stemming; removing stop word, punctuation, number, and empty string.\n",
    "\n",
    "    Args:\n",
    "        text (str): text\n",
    "\n",
    "    Returns:\n",
    "        list: cleaned text as list of tokenized str\n",
    "    \"\"\"\n",
    "\n",
    "    # to list of token\n",
    "    text = word_tokenize(text)\n",
    "\n",
    "    # stemming and convert to lower case if not proper noun: punctuation and stop word seem to help POS tagging, remove them after stemming\n",
    "    word_tag = pos_tag(text)\n",
    "    porter = PorterStemmer()\n",
    "    text = [\n",
    "        porter.stem(each[0])\n",
    "        if each[1] != \"NNP\" and each[1] != \"NNPS\" else each[0]\n",
    "        for each in word_tag\n",
    "    ]\n",
    "\n",
    "    # remove stop word: it seems stemming skip stop word; OK to remove stop word after stemming;\n",
    "    stop_word = set(stopwords.words('english'))\n",
    "    text = [each for each in text if not each in stop_word]\n",
    "\n",
    "    # remove punctuation\n",
    "    text = [\n",
    "        each.translate(str.maketrans('', '', string.punctuation))\n",
    "        for each in text\n",
    "    ]\n",
    "    # text = re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \" \", text) # if using re\n",
    "\n",
    "    # convert number to <NUM>\n",
    "    text = [\"<NUM>\" if each.isdigit() else each for each in text]\n",
    "\n",
    "    # remove empty string\n",
    "    text = [each for each in text if each != \"\"]\n",
    "\n",
    "    return text\n",
    "\n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = data.copy()\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "        \n",
    "\t\tnames += [f'{data.columns[j]}(t-{i})' for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [f'{data.columns[j]}(t)' for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [f'{data.columns[j]}(t+{i})' for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = pd.concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n",
    "\n",
    "def get_TS_cv(k=5, test_size=None):\n",
    "    \"\"\"\n",
    "    ML models do not need to care about forecast horizon when splitting training and test set. Forecast horizon should be handled by feature preparation ([X_t-1,X_t-2...]). Actually repeated K-fold can also be used, but stick to TS split to align with TS_evaluate().\n",
    "    \"\"\"\n",
    "    return TimeSeriesSplit(\n",
    "        n_splits=k,\n",
    "        gap=0,\n",
    "        test_size=test_size,\n",
    "    )\n",
    "\n",
    "def evaluate_series(y_true, y_pred, horizon):\n",
    "    \"\"\"\n",
    "    Some models (like ARIMA) may not support cross_validate(), compare the forecasting result directly\n",
    "    Args:\n",
    "        y_true: y of test set\n",
    "        y_pred: y of prediction\n",
    "        horizon: forecast horizon\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: single row DF with 3 metrics wrt horizon\n",
    "    \"\"\"\n",
    "    # RMSE\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    # MAE\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    # MAPE\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    r2=r2_score(y_true, y_pred)\n",
    "    forecast_error = {\n",
    "        'h': horizon,\n",
    "        'mae': [mae],\n",
    "        'rmse': [rmse],\n",
    "        'mape': [mape],\n",
    "        'r2':[r2],\n",
    "        'descriptions': \"\"\n",
    "    }\n",
    "    return forecast_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "seed_value = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "h = 1\n",
    "past = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from influxdb_client import InfluxDBClient\n",
    "client= InfluxDBClient.from_config_file(f\"{HOME}/dev/DB/influxdb_config.ini\")\n",
    "query_api = client.query_api()\n",
    "df_WTI = query_api.query_data_frame(\"\"\"\n",
    "from(bucket: \"dummy\")\n",
    "  |> range(start: 2011-04-01, stop: 2019-04-01)\n",
    "  |> filter(fn: (r) => r[\"_measurement\"] == \"WTI\") \n",
    "  |> filter(fn: (r) => r[\"type\"] == \"closing_price\") \n",
    "  |> pivot(rowKey:[\"_time\"], columnKey: [\"_field\"], valueColumn: \"_value\")\n",
    "  |> drop(columns: [\"_start\", \"_stop\"])\n",
    "\"\"\")\n",
    "df_WTI=df_WTI[[\"_time\",\"CLC4\",\"CLC3\",\"CLC2\",\"CLC1\"]]\n",
    "df_WTI.columns=[\"Date\",\"CLC4\",\"CLC3\",\"CLC2\",\"CLC1\"]\n",
    "df_WTI.set_index(\"Date\",inplace=True)\n",
    "df_WTI.index=df_WTI.index.map(lambda each: each.date())\n",
    "df_WTI.index=pd.to_datetime(df_WTI.index)\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month=[each.month for each in df_WTI.index]\n",
    "day=[each.day for each in df_WTI.index]\n",
    "day_in_week=[each.weekday() for each in df_WTI.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dt=pd.DataFrame()\n",
    "df_dt[\"month\"]=month\n",
    "df_dt[\"day\"]=day\n",
    "df_dt[\"day_in_week\"]=day_in_week\n",
    "df_dt.index=df_WTI.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WTI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "mongo_db = mongo_client[\"lima\"]\n",
    "mongo_collection = mongo_db[\"investing_news\"]\n",
    "cursor = mongo_collection.find({\"News\":{\"$ne\":\"NEURONswap: First Dex To Implement Governance 2.0\"}})\n",
    "df_news_com =  pd.DataFrame(list(cursor))[[\"Date\",\"News\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_collection = mongo_db[\"investing_news_world\"]\n",
    "cursor = mongo_collection.find({\"News\":{\"$ne\":\"NEURONswap: First Dex To Implement Governance 2.0\"}})\n",
    "df_news_world=  pd.DataFrame(list(cursor))[[\"Date\",\"News\"]]\n",
    "\n",
    "# mongo_collection = mongo_db[\"investing_news_econ\"]\n",
    "# cursor = mongo_collection.find({\"News\":{\"$ne\":\"NEURONswap: First Dex To Implement Governance 2.0\"}})\n",
    "# df_news_econ=  pd.DataFrame(list(cursor))[[\"Date\",\"News\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news=pd.concat([df_news_com,df_news_world])\n",
    "df_news=df_news.sort_values(by='Date',ignore_index=True)\n",
    "df_news.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_model = fasttext.load_model(f\"{HOME}/data/big/cc.en.300.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news=df_news[df_news.Date.isin(df_WTI.index)]\n",
    "df_news.News = df_news.News.apply(lambda r: \" \".join(clean(r)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sentiment features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_aggregated(df):\n",
    "    df=df.copy()\n",
    "    df[\"Polarity\"] = df.apply(\n",
    "        lambda row: TextBlob(row['News']).sentiment.polarity, axis=1)\n",
    "    df[\"Subjectivity\"] = df.apply(\n",
    "        lambda row: TextBlob(row['News']).sentiment.subjectivity, axis=1)\n",
    "    df_daily_averaged_sentiment_score = df.groupby(['Date']).mean()\n",
    "    return df_daily_averaged_sentiment_score\n",
    "\n",
    "df_sentiment = get_sentiment_aggregated(df_news)\n",
    "df_sentiment[\"Combined_Sentiment\"]=df_sentiment.Polarity*(1+df_sentiment.Subjectivity)\n",
    "def decay_features(df):\n",
    "    window_size=5\n",
    "    feature_list=[]\n",
    "    for each in df.columns:\n",
    "        feature_list.append(df[each].iloc[:window_size].to_list())\n",
    "    feature_num=len(feature_list)\n",
    "    for idx in range(window_size,len(df_sentiment)):\n",
    "        feature_tmp=np.zeros(feature_num)\n",
    "        for t in range(window_size):\n",
    "            for feature_idx in range(feature_num):\n",
    "                feature_tmp[feature_idx]+=df.iloc[idx-t][df.columns[feature_idx]]*((window_size-t)/window_size)\n",
    "        for feature_idx in range(feature_num):\n",
    "            feature_list[feature_idx].append(feature_tmp[feature_idx])\n",
    "    df_result=pd.DataFrame(feature_list).transpose()\n",
    "    df_result.index=df.index\n",
    "    df_result.columns=[f\"Decay_{each}\" for each in df.columns]\n",
    "    return df_result\n",
    "\n",
    "df_res=decay_features(df_sentiment)\n",
    "df_sentiment=pd.concat([df_sentiment,df_res],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sentiment.to_pickle(\"df_sentiment_2type.pkl\")\n",
    "# df_sentiment=pd.read_pickle(\"df_sentiment_3type.pkl\")\n",
    "# df_sentiment=pd.read_pickle(\"df_sentiment.pkl\")\n",
    "df_sentiment.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### topic modeling features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_aggregated(df):\n",
    "    df=df.copy()\n",
    "    news_emb = df.News.apply(lambda x: fasttext_model.get_sentence_vector(\n",
    "        (x))).to_numpy().tolist()\n",
    "    news_emb = np.array(news_emb)\n",
    "    emb_scaler=MinMaxScaler()\n",
    "    news_emb=emb_scaler.fit_transform(news_emb)\n",
    "    lda_model=LatentDirichletAllocation(n_components=5,n_jobs=-1)\n",
    "    topic= lda_model.fit_transform(news_emb)\n",
    "    for i in range(5):\n",
    "        df[f\"Topic{i+1}\"] = topic[:, i]\n",
    "    df_daily_averaged_topic = df.groupby(['Date']).mean()\n",
    "    return df_daily_averaged_topic, emb_scaler, lda_model\n",
    "\n",
    "df_topic, emb_scaler, lda_model = get_topic_aggregated(df_news)\n",
    "df_topic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res=decay_features(df_topic)\n",
    "df_topic=pd.concat([df_topic,df_res],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_topic.to_pickle(\"df_topic_2type.pkl\")\n",
    "# df_topic=pd.read_pickle(\"df_topic_2type.pkl\")\n",
    "# df_topic=pd.read_pickle(\"df_topic.pkl\")\n",
    "df_topic.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GeoIdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "geo_pattern={\n",
    "\"Geopolitical_Threats\":\"Geopolitical risk concern tension uncertainty United States tensions military war geopolitical coup guerrilla warfare Latin America Central America South America Europe Africa Middle East Far East Asia\",\n",
    "\"Nuclear_Threats\":\"nuclear war atomic war nuclear conflict atomic conflict nuclear missile fear threat risk peril menace\",\n",
    "\"War_Threats\":\"war risk risk of war fear of war war fear military threat war threat threat of war military action military operation military fce risk threat\",\n",
    "\"Terrorist_Threats\":\"terrorist threat threat of terrorism terrorism menace menace of terrorism terrorist risk terr risk risk of terrorism terr threat\",\n",
    "\"War_Acts\":\"beginning of the war outbreak of the war onset of the war escalation of the war start of the war war military air strike war battle heavy casualties\",\n",
    "\"Terrorist_Acts\":\"terrorist act terrorist acts\"}\n",
    "\n",
    "def get_geoidx_aggregated(df):\n",
    "    df=df.copy()\n",
    "    df[\"news_emb\"] = df.News.apply(lambda x: fasttext_model.get_sentence_vector(\n",
    "        (x))).to_numpy().tolist()\n",
    "    for each in geo_pattern:\n",
    "        pattern_emb=fasttext_model.get_sentence_vector(each)\n",
    "        df[each]=df.news_emb.apply(lambda x:1-spatial.distance.cosine(pattern_emb, x))\n",
    "    df=df.drop([\"News\",\"news_emb\"],axis=1)\n",
    "    df_daily_averaged_geoidx = df.groupby(['Date']).max()\n",
    "    return df_daily_averaged_geoidx\n",
    "\n",
    "df_geoidx = get_geoidx_aggregated(df_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res=decay_features(df_geoidx)\n",
    "df_geoidx=pd.concat([df_geoidx,df_res],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_geoidx.to_pickle(\"df_geoidx_2type.pkl\")\n",
    "df_geoidx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Xy = pd.concat([df_sentiment,df_topic, df_geoidx,df_WTI], axis=1, join=\"inner\")\n",
    "print(df_Xy.shape)\n",
    "df_Xy.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_emb_maxmin(emb):\n",
    "    data=np.array(emb.to_numpy().tolist())\n",
    "    return np.concatenate([data.max(axis=0),data.min(axis=0)])\n",
    "def aggregate_emb_maxmeanmin(emb):\n",
    "    data=np.array(emb.to_numpy().tolist())\n",
    "    return np.concatenate([data.max(axis=0),data.mean(axis=0),data.min(axis=0)])\n",
    "\n",
    "news_emb = df_news.News.apply(lambda x: fasttext_model.get_sentence_vector(\n",
    "        (x)))\n",
    "# news_emb = np.array(news_emb)\n",
    "# emb_scaler=MinMaxScaler()\n",
    "# news_emb=emb_scaler.fit_transform(news_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emb=pd.concat([df_news.Date,news_emb],axis=1)\n",
    "df_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# daily mean of mean\n",
    "# df_emb[\"News\"]=df_emb.News.apply(lambda r:np.array(r.tolist()).mean())\n",
    "\n",
    "# daily mean\n",
    "# df_emb=df_emb.groupby(\"Date\").mean()\n",
    "\n",
    "# max + min\n",
    "# df_emb=df_emb.groupby(\"Date\")['News'].agg(aggregate_emb_maxmin)\n",
    "\n",
    "# max + mean + min\n",
    "df_emb=df_emb.groupby(\"Date\")['News'].agg(aggregate_emb_maxmeanmin)\n",
    "\n",
    "df_emb=pd.DataFrame(df_emb)\n",
    "# df_emb.set_index(\"Date\",inplace=True)\n",
    "df_emb.index=pd.to_datetime(df_emb.index)\n",
    "df_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to align\n",
    "df_emb=df_emb[df_emb.index.isin(df_WTI[\"CLC1\"].index)]\n",
    "# emb=df_emb.to_numpy()\n",
    "# emb =np.array([each.tolist() for each in emb])\n",
    "# emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y=df_WTI[df_WTI.index.isin(df_emb.index)][\"CLC1\"].to_numpy()\n",
    "# y.shape\n",
    "# feature_name=\"EMB_maxmeanmin_single\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CORENLP_HOME\"]=\"~/.stanfordnlp_resources/stanford-corenlp-4.1.0/\"\n",
    "from openie import StanfordOpenIE\n",
    "openie_client= StanfordOpenIE()\n",
    "openie_client.client.ensure_alive()\n",
    "# df_news.to_pickle(\"df_news_3type.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_tuples = []\n",
    "for idx, row in df_news.iterrows():\n",
    "    text = row['News']\n",
    "    for triple in openie_client.annotate(text):\n",
    "        triple['Date'] = row['Date']\n",
    "        event_tuples.append(triple)\n",
    "openie_client.client.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events = pd.DataFrame(event_tuples)\n",
    "# df_events.to_pickle(\"df_events_2type.pkl\")\n",
    "# df_events=pd.read_pickle(\"df_events.pkl\")\n",
    "# df_events=pd.read_pickle(\"df_events_2type.pkl\")\n",
    "# df_events=pd.read_pickle(\"df_events_3type.pkl\")\n",
    "df_events.subject = df_events.subject.apply(\n",
    "    lambda x: fasttext_model.get_sentence_vector((x)))\n",
    "df_events.relation = df_events.relation.apply(\n",
    "    lambda x: fasttext_model.get_sentence_vector((x)))\n",
    "df_events.object = df_events.object.apply(lambda x: fasttext_model.get_sentence_vector(\n",
    "    (x)))\n",
    "df_events.dropna(inplace=True)\n",
    "df_events.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_emb_maxmeanmin(emb):\n",
    "    data=np.array(emb.to_numpy().tolist())\n",
    "    return np.concatenate([data.max(axis=0),data.mean(axis=0),data.min(axis=0)])\n",
    "\n",
    "# max + mean + min\n",
    "series_subject=df_events.groupby(\"Date\")['subject'].agg(aggregate_emb_maxmeanmin)\n",
    "series_relation=df_events.groupby(\"Date\")['relation'].agg(aggregate_emb_maxmeanmin)\n",
    "series_object=df_events.groupby(\"Date\")['object'].agg(aggregate_emb_maxmeanmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_event_emb=pd.concat([series_subject,series_relation,series_object],axis=1)\n",
    "df_event_emb.index=pd.to_datetime(df_event_emb.index)\n",
    "df_event_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to align\n",
    "# df_event_emb=df_event_emb[df_event_emb.index.isin(df_WTI[\"CLC1\"].index)]\n",
    "# join 3 : (-1,2700)\n",
    "# df_event_emb[\"event\"]=df_event_emb.apply(np.concatenate,axis=1)\n",
    "# join 3 : (-1,3,900)\n",
    "df_event_emb[\"event\"]=df_event_emb.apply(np.array,axis=1)\n",
    "# event_emb=df_event_emb[\"event\"].to_numpy()\n",
    "# event_emb=np.array([each.tolist() for each in event_emb])\n",
    "# X=event_emb\n",
    "# event_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_event_emb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Xy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stationary test before diff\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "for i in range(df_Xy.shape[1]):\n",
    "    test_result=adfuller(df_Xy[df_Xy.columns[i]].to_numpy())\n",
    "    if test_result[1]>0.05:\n",
    "        print(f\"{df_Xy.columns[i]}: {test_result[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adfuller(df_Xy['CLC1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Xy.columns[:]\n",
    "# df_Xy.columns[7:]#\n",
    "df_Xy.columns[:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'aic': 25, 'bic': 5, 'hqic': 5, 'fpe': 25}\n",
      "{'aic': 10, 'bic': 5, 'hqic': 5, 'fpe': 10}\n",
      "{'aic': 5, 'bic': 1, 'hqic': 1, 'fpe': 5}\n",
      "{'aic': 23, 'bic': 2, 'hqic': 2, 'fpe': 23}\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.api import VAR\n",
    "# endo=df_Xy[df_Xy.columns[-4:]].to_numpy()\n",
    "# exo=df_Xy[df_Xy.columns[:-4]].to_numpy()\n",
    "endo=df_Xy[[\"Polarity\",\"Subjectivity\",'Combined_Sentiment',\"CLC1\"]].to_numpy()\n",
    "exo=None\n",
    "model = VAR(endog=endo,exog=exo)\n",
    "var_result=model.select_order(50)\n",
    "print(var_result.selected_orders)\n",
    "\n",
    "endo=df_Xy[[\"Topic1\",\"Topic2\",\"Topic3\",\"Topic4\",\"CLC1\"]].to_numpy()\n",
    "model = VAR(endog=endo,exog=exo)\n",
    "var_result=model.select_order(50)\n",
    "print(var_result.selected_orders)\n",
    "\n",
    "endo=df_Xy[[\"Geopolitical_Threats\",\"Nuclear_Threats\",\"War_Threats\",\"Terrorist_Threats\",'War_Acts','Terrorist_Acts ',\"CLC1\"]].to_numpy()\n",
    "model = VAR(endog=endo,exog=exo)\n",
    "var_result=model.select_order(50)\n",
    "print(var_result.selected_orders)\n",
    "\n",
    "endo=df_Xy[[\"CLC4\",\"CLC3\",\"CLC2\",\"CLC1\"]].to_numpy()\n",
    "model = VAR(endog=endo,exog=exo)\n",
    "var_result=model.select_order(50)\n",
    "print(var_result.selected_orders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'aic': 5, 'bic': 1, 'hqic': 1, 'fpe': 5}\n"
     ]
    }
   ],
   "source": [
    "endo=df_Xy[['Polarity', 'Subjectivity', 'Combined_Sentiment',\n",
    "         'Topic1', 'Topic2',\n",
    "       'Topic3', 'Topic4',\n",
    "         'Geopolitical_Threats',\n",
    "       'Nuclear_Threats', 'War_Threats', 'Terrorist_Threats', 'War_Acts',\n",
    "       'Terrorist_Acts ',\n",
    "       \"CLC4\",\"CLC3\",\"CLC2\",\"CLC1\"]].to_numpy()\n",
    "model = VAR(endog=endo,exog=exo)\n",
    "var_result=model.select_order(50)\n",
    "print(var_result.selected_orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2011-04-01', '2011-04-04', '2011-04-05', '2011-04-06',\n",
       "               '2011-04-07', '2011-04-08', '2011-04-11', '2011-04-12',\n",
       "               '2011-04-13', '2011-04-14',\n",
       "               ...\n",
       "               '2019-03-18', '2019-03-19', '2019-03-20', '2019-03-21',\n",
       "               '2019-03-22', '2019-03-25', '2019-03-26', '2019-03-27',\n",
       "               '2019-03-28', '2019-03-29'],\n",
       "              dtype='datetime64[ns]', name='Date', length=2014, freq=None)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Xy.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aic': 23, 'bic': 2, 'hqic': 2, 'fpe': 23}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endo=df_Xy[df_Xy.columns[-4:]].to_numpy()\n",
    "exo=df_Xy[df_Xy.columns[:-4]].to_numpy()\n",
    "model = VAR(endog=endo,exog=exo)\n",
    "var_result=model.select_order(30)\n",
    "var_result.selected_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in df_Xy.columns[:-1]:\n",
    "    try:\n",
    "        endo=df_Xy[[\"CLC1\",each]].to_numpy()\n",
    "        model = VAR(endo)\n",
    "        var_result=model.select_order(120)\n",
    "        print(f\"{each}: {var_result.selected_orders}\")\n",
    "    except:\n",
    "        print(f\"ERROR: {each}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.tsa\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "plot_acf(df_Xy.CLC3,lags=9, alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "all_results=[]\n",
    "for each in df_Xy.columns:\n",
    "    if each ==\"CLC1\":\n",
    "        continue\n",
    "    rest_results=grangercausalitytests(df_Xy[[\"CLC1\",each]],maxlag=20,verbose=False)\n",
    "    for lag in range(1,20):\n",
    "        all_results.append({\"type\":each,\"lag\":lag, \"p\":rest_results[lag][0]['ssr_ftest'][1]})\n",
    "df_test=pd.DataFrame(all_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.sort_values(\"p\")[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name=\"day\"\n",
    "df_selected=df_Xy#[[feature_name,'CLC1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection with Granger\n",
    "# df_g_test=df.sort_values(\"p\")\n",
    "# selected_features_series=[]\n",
    "# for idx,each in df_g_test.iterrows():\n",
    "#     series=df_Xy[each[\"type\"]].shift(each[\"lag\"])\n",
    "#     series.name=f\"{each['type']}(t-{each['lag']})\"\n",
    "#     selected_features_series.append(series)\n",
    "# df_selected=pd.concat(selected_features_series,axis=1).dropna()\n",
    "# df_selected.columns[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected[df_selected.columns[:1]].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preserve original price for inverting prediction\n",
    "df_original_price = df_Xy[[\"CLC1\"]].shift(h).dropna()\n",
    "# 1st order DIFF\n",
    "df_selected = df_Xy.diff().dropna()\n",
    "df_nodiff = df_Xy.dropna()\n",
    "# shift back $past days\n",
    "past=20\n",
    "df_selected = series_to_supervised(df_selected, past, h)\n",
    "df_nodiff = series_to_supervised(df_nodiff, past, h)\n",
    "# df_selected = series_to_supervised(df_emb, past, h)\n",
    "\n",
    "df_original_price = df_original_price[df_original_price.index.isin(df_selected.index)]\n",
    "# remove current day features for forecast\n",
    "for each in df_selected.columns[:-1]:\n",
    "    if \"(t)\" in each:\n",
    "        df_selected.drop(each, axis=1, inplace=True)\n",
    "        df_nodiff.drop(each, axis=1, inplace=True)\n",
    "        \n",
    "\n",
    "# add time feature without shift \n",
    "df_selected=pd.concat([df_dt,df_selected],axis=1).dropna()\n",
    "df_nodiff=pd.concat([df_dt,df_nodiff],axis=1).dropna()\n",
    "df_nodiff=df_nodiff[df_nodiff.index.isin(df_selected.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stationary test after diff\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "for i in range(df_selected.shape[1]):\n",
    "    test_result=adfuller(df_selected[df_selected.columns[i]].to_numpy())\n",
    "    if test_result[1]>0.05:\n",
    "        print(f\"{df_selected.columns[i]}: {test_result[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # EMB\n",
    "# df_emb = series_to_supervised(df_emb, past, h)\n",
    "# for each in df_emb.columns:\n",
    "#     if \"(t)\" in each:\n",
    "#         df_emb.drop(each, axis=1, inplace=True)\n",
    "# df_emb = df_emb[df_emb.index.isin(df_selected.index)]\n",
    "# df_emb.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# event-EMB\n",
    "df_selected_emb = series_to_supervised(df_event_emb[[\"event\"]], past, h)\n",
    "for each in df_selected_emb.columns:\n",
    "    if \"(t)\" in each:\n",
    "        df_selected_emb.drop(each, axis=1, inplace=True)\n",
    "df_selected_emb = df_selected_emb[df_selected_emb.index.isin(df_selected.index)]\n",
    "df_selected_emb.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected=df_selected[df_selected.index.isin(df_selected_emb.index)]\n",
    "df_nodiff=df_nodiff[df_nodiff.index.isin(df_selected_emb.index)]\n",
    "df_original_price=df_original_price[df_original_price.index.isin(df_selected_emb.index)]\n",
    "print(f\"{df_selected.shape} | {df_original_price.shape}\")\n",
    "print(f\"{df_selected.shape} | {df_nodiff.shape}\")\n",
    "print(f\"{df_selected.shape} | {df_selected_emb.shape}\")\n",
    "(df_selected_emb.index==df_selected.index).all()\n",
    "# df_selected.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emb =np.array([each.tolist() for each in df_emb.to_numpy()])\n",
    "event_emb= df_selected_emb.to_numpy()\n",
    "event_emb =np.array([each.tolist() for each in event_emb])\n",
    "event_emb =np.array([each.tolist() for each in event_emb])\n",
    "print(f\"{event_emb.shape} | {event_emb.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_X = df_selected.to_numpy()[:, :-1]\n",
    "no_diff_raw_X = df_nodiff.to_numpy()[:, :-1]\n",
    "y =  df_selected.to_numpy()[:, -1].reshape(-1, 1) \n",
    "no_diff_y =  df_nodiff.to_numpy()[:, -1].reshape(-1, 1) \n",
    "# y = df_Xy[df_Xy.index.isin(df_selected.index)].to_numpy()[:, -1].reshape(-1, 1)\n",
    "# y=df_WTI[df_WTI.index.isin(df_selected.index)][\"CLC1\"].to_numpy().reshape(-1, 1)\n",
    "f\"{raw_X.shape} |{no_diff_raw_X.shape} |{y.shape}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for embedding\n",
    "# raw_X=np.array([each.tolist() for each in raw_X])\n",
    "# raw_X=np.array([each.tolist() for each in raw_X])\n",
    "# raw_X.shape\n",
    "# X=raw_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump for ARIMA\n",
    "# df_dump=df_Xy[df_Xy.index.isin(df_selected.index)]\n",
    "# df_dump.to_pickle(\"df_dump.pkl\")\n",
    "# df_Xy=pd.read_pickle(\"df_dump.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression,RFE,RFECV,SelectFromModel,SequentialFeatureSelector,chi2,SelectKBest,f_regression,VarianceThreshold,r_regression\n",
    "from sklearn.linear_model import Ridge,Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor,ExtraTreeRegressor\n",
    "from sklearn.svm import LinearSVR,SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{raw_X.shape} | {y.shape}\")\n",
    "print(f\"{no_diff_raw_X.shape} | {no_diff_y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tsfel.feature_extraction.features import entropy,abs_energy,autocorr,neighbourhood_peaks\n",
    "# # tsfel.feature_extraction.features.abs_energy()\n",
    "# def tswrapper(a,b):\n",
    "#     # a=MinMaxScaler().fit_transform(raw_X)\n",
    "#     result=pd.DataFrame(a).apply(autocorr).to_numpy()\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selector based\n",
    "# estimator = Lasso(random_state=42)\n",
    "# estimator = DecisionTreeRegressor(random_state=42)\n",
    "estimator = Ridge(random_state=42)\n",
    "# estimator = LinearRegression()\n",
    "# estimator = LinearSVR(tol=0.001,random_state=42)\n",
    "# selector = RFE(estimator,n_features_to_select=20,step=1)\n",
    "# selector = RFECV(estimator, min_features_to_select=20, cv=get_TS_cv(),step=1,n_jobs=-1)\n",
    "# selector=SelectFromModel(estimator,max_features=20)\n",
    "selector=SequentialFeatureSelector(estimator,n_features_to_select=20,direction='forward',n_jobs=-1,cv=get_TS_cv())\n",
    "# selector=SelectKBest(mutual_info_regression,k=20)\n",
    "# selector=SelectKBest(tswrapper,k=20)\n",
    "# selector=VarianceThreshold(3.21)\n",
    "scaled_raw_X=MinMaxScaler().fit_transform(no_diff_raw_X)\n",
    "# scaled_y=MinMaxScaler().fit_transform(y)\n",
    "# selector = selector.fit(scaled_raw_X,scaled_y.ravel())\n",
    "selector = selector.fit(scaled_raw_X,no_diff_y.ravel())\n",
    "# selector = selector.fit(no_diff_raw_X,no_diff_y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1958, 20) | (1958, 1)\n",
      "(1958, 20) | (1958, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['day', 'Decay_Topic1(t-18)', 'Subjectivity(t-17)', 'CLC1(t-17)',\n",
       "       'Topic5(t-12)', 'Subjectivity(t-11)', 'Topic1(t-11)', 'Topic3(t-9)',\n",
       "       'Decay_Topic5(t-9)', 'Decay_Topic5(t-8)', 'Topic5(t-5)',\n",
       "       'Terrorist_Threats(t-5)', 'Topic5(t-4)', 'Topic5(t-3)', 'CLC1(t-3)',\n",
       "       'Topic4(t-2)', 'CLC1(t-2)', 'CLC3(t-1)', 'CLC2(t-1)', 'CLC1(t-1)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = raw_X[:, selector.get_support()]\n",
    "no_diff_X = no_diff_raw_X[:, selector.get_support()]\n",
    "# X = raw_X\n",
    "feature_name=f\"20_{X.shape[-1]}\"\n",
    "print(f\"{X.shape} | {y.shape}\")\n",
    "print(f\"{no_diff_X.shape} | {no_diff_y.shape}\")\n",
    "df_selected.columns[:-1][selector.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA,FastICA,FactorAnalysis,NMF\n",
    "# scaled_raw_X=MinMaxScaler((1,100)).fit_transform(raw_X)\n",
    "# # pca = PCA(n_components=150,svd_solver='full')\n",
    "# pca = NMF(n_components=150,max_iter=1000)\n",
    "# # decomposer = FactorAnalysis(n_components=7)\n",
    "# X=pca.fit_transform(scaled_raw_X)\n",
    "# feature_name=f\"NMF_{X.shape[-1]}\"\n",
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X=raw_X\n",
    "# X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df_Xy['CLC1'].to_numpy().ravel()\n",
    "# X=df_Xy[['CLC2','CLC3','CLC4']].to_numpy()\n",
    "X=df_geoidx.to_numpy()\n",
    "# X=df_Xy[['CLC2','CLC3','CLC4']].to_numpy()\n",
    "f\"{X.shape} | {y.shape}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X=np.random.random((2014, 12))\n",
    "X=np.zeros((2014, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forecast Error (10-fold cross-validated performance):\n",
      "LinearRegression:\n",
      "MAE = 1.013 +/- 0.223\n",
      "RMSE = 1.299 +/- 0.277\n",
      "MAPE = 0.017 +/- 0.005\n",
      "\n",
      "LinearRegression,1.013414,1.299189,0.016872\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import LinearRegression, ARDRegression, SGDRegressor, ElasticNet, Lars, Lasso, GammaRegressor, TweedieRegressor, PoissonRegressor, Ridge, BayesianRidge\n",
    "from sklearn.ensemble import AdaBoostRegressor,RandomForestRegressor\n",
    "\n",
    "# lin_model=SGDRegressor(random_state =42)    #LinearRegression,Ridge,LinearSVR\n",
    "lin_model=LinearRegression()  \n",
    "model_name=lin_model.__class__.__name__\n",
    "\n",
    "# msg=f\"{model_name}_{feature_name}\"\n",
    "msg=f\"{model_name}\"\n",
    "\n",
    "X_scaler = MinMaxScaler()\n",
    "# scaled_X=X_scaler.fit_transform(X)\n",
    "scaled_X=X_scaler.fit_transform(no_diff_X)\n",
    "# scaled_X=X\n",
    "\n",
    "cv_results = cross_validate(lin_model,\n",
    "                                scaled_X,\n",
    "                                no_diff_y,\n",
    "                                scoring=[\n",
    "                                    'neg_mean_absolute_error',\n",
    "                                    'neg_root_mean_squared_error',\n",
    "                                    'neg_mean_absolute_percentage_error'\n",
    "                                ],\n",
    "                                cv=get_TS_cv(),\n",
    "                                n_jobs=-1)\n",
    "mae = -cv_results[\"test_neg_mean_absolute_error\"]\n",
    "rmse = -cv_results[\"test_neg_root_mean_squared_error\"]\n",
    "mape = -cv_results[\"test_neg_mean_absolute_percentage_error\"]\n",
    "k = 5\n",
    "print(f\"\"\"\n",
    "Forecast Error ({k}-fold cross-validated performance):\n",
    "{lin_model.__class__.__name__}:\n",
    "MAE = {mae.mean():.3f} +/- {mae.std():.3f}\n",
    "RMSE = {rmse.mean():.3f} +/- {rmse.std():.3f}\n",
    "MAPE = {mape.mean():.3f} +/- {mape.std():.3f}\n",
    "\"\"\")\n",
    "print(f\"{msg},{mae.mean():.6f},{rmse.mean():.6f},{mape.mean():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Reshape,MaxPooling2D,Bidirectional,ConvLSTM2D\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import GRU\n",
    "from keras.layers import SimpleRNN \n",
    "from keras.layers import Conv2D,Conv3D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Input\n",
    "from keras.layers import Flatten\n",
    "from keras.models import Model\n",
    "from keras.layers.merge import concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hold-out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(1958, 20) | (1958, 1) | (1958, 20, 3, 900)'"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X=event_emb.reshape(-1,3,emb.shape[-1])\n",
    "# y=y.reshape(-1,1)\n",
    "# X=X.reshape(-1,10,900)\n",
    "# X=X.reshape(-1,10,3,900)\n",
    "emb=event_emb\n",
    "f\"{X.shape} | {y.shape} | {emb.shape}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X: (1957, 1, 20)\t val_X: (1, 1, 20)\t test_X:(653, 1, 20)\n",
      "train_emb: (1957, 20, 3, 900)\t val_emb: (1, 20, 3, 900)\t test_emb:(653, 20, 3, 900)\n",
      "train_y: (1957, 1)\t val_y: (1, 1) test_y:(653, 1)\n"
     ]
    }
   ],
   "source": [
    "length=X.shape[0]\n",
    "train_size=int(length*2/3)\n",
    "# val_size=int(train_size*0.1)\n",
    "val_size=1\n",
    "step_size=1\n",
    "\n",
    "# train_X=no_diff_X[:train_size]\n",
    "train_X=X[:train_size]\n",
    "train_emb=emb[:train_size,:,:]\n",
    "train_y=y[:train_size,:]\n",
    "# test_X=no_diff_X[train_size:]\n",
    "test_X=X[train_size:]\n",
    "test_emb=emb[train_size:,:,:]\n",
    "test_y=y[train_size:,:]\n",
    "\n",
    "val_X=train_X[-val_size:]\n",
    "val_emb=train_emb[-val_size:,:,:]\n",
    "val_y=train_y[-val_size:,:]\n",
    "train_X=X[:-val_size]\n",
    "train_emb=emb[:-val_size,:,:]\n",
    "train_y=y[:-val_size,:]\n",
    "\n",
    "\n",
    "X_scaler = MinMaxScaler()\n",
    "X_scaler.fit(train_X)\n",
    "y_scaler = MinMaxScaler(feature_range=(1, 100))\n",
    "# y_scaler = MinMaxScaler()\n",
    "y_scaler.fit(train_y)\n",
    "\n",
    "train_X=X_scaler.transform(train_X)\n",
    "test_X=X_scaler.transform(test_X)\n",
    "val_X=X_scaler.transform(val_X)\n",
    "train_y=y_scaler.transform(train_y)\n",
    "test_y=y_scaler.transform(test_y)\n",
    "val_y=y_scaler.transform(val_y)\n",
    "\n",
    "train_X=train_X.reshape(train_X.shape[0],step_size,train_X.shape[-1])\n",
    "test_X=test_X.reshape(test_X.shape[0],step_size,test_X.shape[-1])\n",
    "val_X=val_X.reshape(val_X.shape[0],step_size,val_X.shape[-1])\n",
    "print(f\"train_X: {train_X.shape}\\t val_X: {val_X.shape}\\t test_X:{test_X.shape}\")\n",
    "print(f\"train_emb: {train_emb.shape}\\t val_emb: {val_emb.shape}\\t test_emb:{test_emb.shape}\")\n",
    "print(f\"train_y: {train_y.shape}\\t val_y: {val_y.shape} test_y:{test_y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nbeats_keras.model import NBeatsNet\n",
    "# model = NBeatsNet(\n",
    "#     backcast_length=1, forecast_length=1,\n",
    "#     stack_types=(NBeatsNet.GENERIC_BLOCK, NBeatsNet.GENERIC_BLOCK),\n",
    "#     nb_blocks_per_stack=2, thetas_dim=(4, 4), share_weights_in_stack=True,\n",
    "#     hidden_layer_units=128\n",
    "# )\n",
    "# model.compile(loss='mse', optimizer='adam',run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size=train_emb.shape[-1]\n",
    "emb_inputs = Input(shape=(past,3,emb_size))\n",
    "emb_model = Reshape((1,past,3,3,300))(emb_inputs)\n",
    "emb_model = Conv3D(50,(3,2,1), activation=\"relu\",padding='valid')(emb_model)\n",
    "emb_model = Dropout(0.3)(emb_model)\n",
    "emb_model = Conv3D(50,(5,1,2), activation=\"relu\",padding='valid')(emb_model)\n",
    "emb_model = Dropout(0.3)(emb_model)\n",
    "emb_model = Reshape((4,4,-1))(emb_model)\n",
    "emb_model = Conv2D(10,(2,2), activation=\"relu\",padding='valid')(emb_model)\n",
    "emb_model = Dropout(0.3)(emb_model)\n",
    "emb_model = Flatten()(emb_model)\n",
    "# emb_model = Dense(1)(emb_model)\n",
    "emb_model = Model(inputs=emb_inputs, outputs=emb_model)\n",
    "# opt=Adam(0.0007)\n",
    "# model.compile(loss='mae', optimizer=opt)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.backend.clear_session()\n",
    "ts_inputs = Input(shape=(step_size,train_X.shape[-1]))\n",
    "ts_model=Reshape((step_size,train_X.shape[-1]))(ts_inputs)\n",
    "ts_model=GRU(300,dropout=0.33,return_sequences=True)(ts_model)\n",
    "ts_model= Dropout(0.3)(ts_model)\n",
    "ts_model=GRU(300,dropout=0.33,return_sequences=False)(ts_model)\n",
    "ts_model= Dropout(0.3)(ts_model)\n",
    "# ts_model =Dense(1)(ts_model)\n",
    "ts_model = Model(inputs=ts_inputs, outputs=ts_model)\n",
    "# ts_model.compile(loss='mae', optimizer=Adam(0.0005))\n",
    "# ts_model.compile(loss='mae', optimizer=Adam(0.0005))\n",
    "# ts_model.compile(loss='log_cosh', optimizer=Adam(0.0002))\n",
    "# ts_model = Bidirectional(GRU(500,dropout=0.1,return_sequences=False))(ts_inputs)\n",
    "# ts_model= Dropout(0.2)(ts_model)\n",
    "# model = Model(inputs=ts_inputs, outputs=ts_model)\n",
    "# opt = Adam(learning_rate=0.001)\n",
    "# ts_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model = concatenate([ts_model.output,emb_model.output])\n",
    "combined_model= Reshape((1,-1),name='alpha')(combined_model)\n",
    "combined_model= Bidirectional(GRU(100,dropout=0.33,return_sequences=False))(combined_model)\n",
    "combined_model = Dropout(0.3)(combined_model)\n",
    "combined_model = Dense(1)(combined_model)\n",
    "model = Model(inputs=[ts_model.input,emb_model.input], outputs=combined_model)\n",
    "model.compile(loss='log_cosh', optimizer=Adam(0.0002))\n",
    "# model.compile(loss='msle', optimizer=Adam(0.0002))\n",
    "# model.compile(loss='mape', optimizer=Adam(0.0005))\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "49/49 [==============================] - 5s 22ms/step - loss: 52.0361 - val_loss: 32.9931\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 40.1196 - val_loss: 27.5011\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 35.2031 - val_loss: 24.6281\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 32.4937 - val_loss: 22.2054\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 30.0833 - val_loss: 19.8745\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 27.8280 - val_loss: 17.6676\n",
      "Epoch 7/100\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 25.6816 - val_loss: 15.5177\n",
      "Epoch 8/100\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 23.5445 - val_loss: 13.4270\n",
      "Epoch 9/100\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 21.5294 - val_loss: 11.3631\n",
      "Epoch 10/100\n",
      "49/49 [==============================] - 0s 6ms/step - loss: 19.4737 - val_loss: 9.2572\n",
      "Epoch 11/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 17.4802 - val_loss: 7.2312\n",
      "Epoch 12/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 15.6208 - val_loss: 5.2461\n",
      "Epoch 13/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 13.6513 - val_loss: 3.3240\n",
      "Epoch 14/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 11.9532 - val_loss: 1.4806\n",
      "Epoch 15/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 10.5986 - val_loss: 0.0857\n",
      "Epoch 16/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 9.2204 - val_loss: 0.5746\n",
      "Epoch 17/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 8.1306 - val_loss: 1.9373\n",
      "Epoch 18/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 7.4379 - val_loss: 3.1847\n",
      "Epoch 19/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 6.7343 - val_loss: 4.3002\n",
      "Epoch 20/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 6.2737 - val_loss: 5.1827\n",
      "Epoch 21/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.9992 - val_loss: 5.9686\n",
      "Epoch 22/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.8033 - val_loss: 6.5826\n",
      "Epoch 23/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.7806 - val_loss: 7.0585\n",
      "Epoch 24/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.6944 - val_loss: 7.4336\n",
      "Epoch 25/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.5410 - val_loss: 7.7760\n",
      "Epoch 26/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.5775 - val_loss: 7.9308\n",
      "Epoch 27/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.5749 - val_loss: 8.0540\n",
      "Epoch 28/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.6154 - val_loss: 8.1666\n",
      "Epoch 29/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.5781 - val_loss: 8.2758\n",
      "Epoch 30/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.5989 - val_loss: 8.3318\n",
      "Epoch 31/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.4971 - val_loss: 8.3514\n",
      "Epoch 32/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.6445 - val_loss: 8.3807\n",
      "Epoch 33/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.5638 - val_loss: 8.3906\n",
      "Epoch 34/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.5849 - val_loss: 8.4556\n",
      "Epoch 35/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.6667 - val_loss: 8.4267\n",
      "Epoch 36/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.5451 - val_loss: 8.4341\n",
      "Epoch 37/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.5388 - val_loss: 8.4221\n",
      "Epoch 38/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.5550 - val_loss: 8.4087\n",
      "Epoch 39/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.5894 - val_loss: 8.4506\n",
      "Epoch 40/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.5340 - val_loss: 8.4092\n",
      "Epoch 41/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.6340 - val_loss: 8.3756\n",
      "Epoch 42/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.6189 - val_loss: 8.4023\n",
      "Epoch 43/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.5988 - val_loss: 8.4336\n",
      "Epoch 44/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.5540 - val_loss: 8.4442\n",
      "Epoch 45/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.6272 - val_loss: 8.4903\n",
      "Epoch 46/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.6153 - val_loss: 8.4267\n",
      "Epoch 47/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.5448 - val_loss: 8.3529\n",
      "Epoch 48/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.6172 - val_loss: 8.4118\n",
      "Epoch 49/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.5865 - val_loss: 8.5224\n",
      "Epoch 50/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.6332 - val_loss: 8.4676\n",
      "Epoch 51/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.5607 - val_loss: 8.4678\n",
      "Epoch 52/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.5958 - val_loss: 8.4701\n",
      "Epoch 53/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.4711 - val_loss: 8.4415\n",
      "Epoch 54/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.5816 - val_loss: 8.4947\n",
      "Epoch 55/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.6468 - val_loss: 8.4682\n",
      "Epoch 56/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.5908 - val_loss: 8.4435\n",
      "Epoch 57/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.4898 - val_loss: 8.5134\n",
      "Epoch 58/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.5942 - val_loss: 8.5802\n",
      "Epoch 59/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.5481 - val_loss: 8.5239\n",
      "Epoch 60/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.5286 - val_loss: 8.4693\n",
      "Epoch 61/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.6155 - val_loss: 8.4843\n",
      "Epoch 62/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.6386 - val_loss: 8.5028\n",
      "Epoch 63/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.6804 - val_loss: 8.5814\n",
      "Epoch 64/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.6765 - val_loss: 8.5324\n",
      "Epoch 65/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.6032 - val_loss: 8.5221\n",
      "Epoch 66/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.5905 - val_loss: 8.4599\n",
      "Epoch 67/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.6167 - val_loss: 8.4405\n",
      "Epoch 68/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.5755 - val_loss: 8.3373\n",
      "Epoch 69/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.5737 - val_loss: 8.4593\n",
      "Epoch 70/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.6139 - val_loss: 8.5007\n",
      "Epoch 71/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.6259 - val_loss: 8.4468\n",
      "Epoch 72/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.5907 - val_loss: 8.5326\n",
      "Epoch 73/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.5522 - val_loss: 8.5426\n",
      "Epoch 74/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.5707 - val_loss: 8.5856\n",
      "Epoch 75/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.6227 - val_loss: 8.4743\n",
      "Epoch 76/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.6519 - val_loss: 8.3756\n",
      "Epoch 77/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.6242 - val_loss: 8.3597\n",
      "Epoch 78/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.6948 - val_loss: 8.3630\n",
      "Epoch 79/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.4764 - val_loss: 8.5338\n",
      "Epoch 80/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.6042 - val_loss: 8.4836\n",
      "Epoch 81/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.5498 - val_loss: 8.4724\n",
      "Epoch 82/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.5498 - val_loss: 8.3414\n",
      "Epoch 83/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.5287 - val_loss: 8.3648\n",
      "Epoch 84/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.6690 - val_loss: 8.5523\n",
      "Epoch 85/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.5950 - val_loss: 8.5818\n",
      "Epoch 86/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.6147 - val_loss: 8.4365\n",
      "Epoch 87/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.6152 - val_loss: 8.4281\n",
      "Epoch 88/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.5889 - val_loss: 8.3186\n",
      "Epoch 89/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.6105 - val_loss: 8.4256\n",
      "Epoch 90/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.6281 - val_loss: 8.5021\n",
      "Epoch 91/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.6316 - val_loss: 8.4820\n",
      "Epoch 92/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.5999 - val_loss: 8.4811\n",
      "Epoch 93/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.6520 - val_loss: 8.4514\n",
      "Epoch 94/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.5864 - val_loss: 8.4625\n",
      "Epoch 95/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.5941 - val_loss: 8.3677\n",
      "Epoch 96/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.5336 - val_loss: 8.4356\n",
      "Epoch 97/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.6363 - val_loss: 8.4362\n",
      "Epoch 98/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.6382 - val_loss: 8.3148\n",
      "Epoch 99/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.5561 - val_loss: 8.3761\n",
      "Epoch 100/100\n",
      "49/49 [==============================] - 0s 5ms/step - loss: 5.5758 - val_loss: 8.4668\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_forecast_error = pd.DataFrame(\n",
    "        columns=['h', 'mae', 'rmse', 'mape', 'descriptions'])\n",
    "history = model.fit([train_X,train_emb], train_y, epochs=100, batch_size=40, validation_data=([val_X,val_emb], val_y), verbose=1, shuffle=False)\n",
    "# history = model.fit([train_X,train_emb], train_y, epochs=100, batch_size=40, verbose=1, shuffle=False)\n",
    "# history = model.fit(train_X, train_y, epochs=100, batch_size=50, validation_data=(test_X, test_y), verbose=1, shuffle=False)\n",
    "# # plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(653, 1)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y = model.predict([test_X,test_emb])\n",
    "# pred_y = ts_model.predict(test_X)\n",
    "pred_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU_20_20,0.7477011980027939,1.0072120531327282,0.013563949555928167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'h': 1,\n",
       " 'mae': [0.7477011980027939],\n",
       " 'rmse': [1.0072120531327282],\n",
       " 'mape': [0.013563949555928167],\n",
       " 'r2': [0.986438283501746],\n",
       " 'descriptions': ''}"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pred_y=pred_y[:,0,0,0]\n",
    "inverted_pred_y = y_scaler.inverse_transform(pred_y.reshape(test_y.shape))\n",
    "inverted_test_y = y_scaler.inverse_transform(test_y)\n",
    "original_test_price=df_original_price.to_numpy()[train_size:]\n",
    "inverted_pred_y=inverted_pred_y+original_test_price\n",
    "inverted_test_y=inverted_test_y+original_test_price\n",
    "forecast_error=evaluate_series(inverted_test_y, inverted_pred_y, h)\n",
    "\n",
    "print(f\"GRU_{feature_name},{forecast_error['mae'][0]},{forecast_error['rmse'][0]},{forecast_error['mape'][0]}\")\n",
    "forecast_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(forecast_error)\n",
    "df_forecast_error = df_forecast_error.append(\n",
    "    pd.DataFrame(forecast_error), ignore_index=True)\n",
    "mae = df_forecast_error[\"mae\"]\n",
    "rmse = df_forecast_error[\"rmse\"]\n",
    "mape = df_forecast_error[\"mape\"]\n",
    "k = 1\n",
    "msg = f\"\"\"\n",
    "Forecast Error ({k}-fold cross-validation)\n",
    "X: {X.shape}\n",
    "y: {y.shape}\n",
    "h= {h}\n",
    "Model: {model.__class__.__name__}\n",
    "MAE = {mae.mean():.6f} +/- {mae.std():.3f}\n",
    "RMSE = {rmse.mean():.6f} +/- {rmse.std():.3f}\n",
    "MAPE = {mape.mean():.6f} +/- {mape.std():.3f}\n",
    "\"\"\"\n",
    "print(msg)\n",
    "logging.info(msg)\n",
    "evaluation_result = {\n",
    "'h': h,\n",
    "'mae': [mae.mean()],\n",
    "'rmse': [rmse.mean()],\n",
    "'mape': [mape.mean()],\n",
    "'descriptions': [msg]\n",
    "}\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_forecast_error\n",
    "# model.save_weights(\"weights.h5\")\n",
    "model.sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_series(inverted_test_y, inverted_pred_y, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import gzip\n",
    "\n",
    "# with gzip.GzipFile('./trained_models/model.pgz', 'w') as f:\n",
    "#     pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with gzip.open('./trained_models/model.pgz', 'r') as f:\n",
    "#     trained_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_y = trained_model.predict([test_X,test_emb])\n",
    "# inverted_pred_y = y_scaler.inverse_transform(pred_y.reshape(-1, 1))\n",
    "# inverted_test_y = y_scaler.inverse_transform(test_y)  # should be same as testXy\n",
    "# # inverted_pred_y=inverted_pred_y.ravel()+df_original_price.Price.to_numpy()[train_size:]\n",
    "# # inverted_test_y=inverted_test_y.ravel()+df_original_price.Price.to_numpy()[train_size:]\n",
    "# forecast_error = evaluate_series(inverted_test_y, inverted_pred_y, h)\n",
    "# forecast_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export architecture as json \n",
    "# model.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare models\n",
    "step_size=1\n",
    "ts_size=X.shape[-1]\n",
    "\n",
    "ts_inputs = Input(shape=(step_size,ts_size),name='ts_input')\n",
    "# ts_model = Bidirectional(GRU(300,dropout=0.3,return_sequences=False))(ts_inputs)\n",
    "# ts_model = LSTM(300,dropout=0.3,return_sequences=False)(ts_inputs)\n",
    "# ts_model = Bidirectional(GRU(300,dropout=0.4,return_sequences=False))(ts_model)\n",
    "# ts_model= Dropout(0.4)(ts_model)\n",
    "ts_model=Reshape((step_size,ts_size))(ts_inputs)\n",
    "ts_model=GRU(300,dropout=0.33,return_sequences=True)(ts_model)\n",
    "ts_model= Dropout(0.3)(ts_model)\n",
    "ts_model=GRU(300,dropout=0.33,return_sequences=False)(ts_model)\n",
    "ts_model= Dropout(0.3)(ts_model)\n",
    "# ts_model=Bidirectional(ConvLSTM2D(300,(1,5),dropout=0.3,return_sequences=False))(ts_model)\n",
    "# ts_model=ConvLSTM2D(300,(1,5),dropout=0.3,return_sequences=True)(ts_model)\n",
    "# ts_model=ConvLSTM2D(300,(1,5),dropout=0.3,return_sequences=False)(ts_model)\n",
    "# ts_model=Reshape((10,100))(ts_model)\n",
    "# ts_model = Bidirectional(GRU(200,dropout=0.1,return_sequences=True))(ts_model)\n",
    "# ts_model = Bidirectional(GRU(100,dropout=0.1,return_sequences=False))(ts_model)\n",
    "# ts_model = Dense(1)(ts_model)\n",
    "# ts_model=Reshape((1,-1))(ts_model)\n",
    "# ts_model = Dense(1)(ts_model)\n",
    "ts_model = Model(inputs=ts_inputs, outputs=ts_model)\n",
    "# model.compile(loss='mape', optimizer='adam')\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size=emb.shape[-1]\n",
    "emb_inputs = Input(shape=(past,3,emb_size),name='emb_input')\n",
    "emb_model = Reshape((1,past,3,3,300),name='emb_reshape')(emb_inputs)\n",
    "emb_model = Conv3D(50,(3,2,1), activation=\"relu\",padding='valid')(emb_model)\n",
    "emb_model = Dropout(0.3)(emb_model)\n",
    "emb_model = Conv3D(50,(5,1,2), activation=\"relu\",padding='valid')(emb_model)\n",
    "emb_model = Dropout(0.3)(emb_model)\n",
    "emb_model = Reshape((4,4,-1))(emb_model)\n",
    "emb_model = Conv2D(10,(2,2), activation=\"relu\",padding='valid')(emb_model)\n",
    "emb_model = Dropout(0.3)(emb_model)\n",
    "# emb_model = Reshape((1,18,-1))(emb_model)\n",
    "# emb_model = Dropout(0.4)(emb_model) \n",
    "# emb_model = Dropout(0.4)(emb_model) \n",
    "emb_model = Flatten()(emb_model)\n",
    "# emb_model = Dense(1)(emb_model)\n",
    "# opt=Adam(0.0007)\n",
    "emb_model = Model(inputs=emb_inputs, outputs=emb_model)\n",
    "# emb_model.compile(loss='mae', optimizer=opt)\n",
    "# emb_model = Dense(10)(emb_model)\n",
    "# emb_model.compile(loss='mape', optimizer='adam')\n",
    "# emb_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model = concatenate([ts_model.output,emb_model.output])\n",
    "combined_model= Reshape((1,-1),name='alpha')(combined_model)\n",
    "combined_model= Bidirectional(GRU(100,dropout=0.33,return_sequences=False))(combined_model)\n",
    "# combined_model= Bidirectional(GRU(200,dropout=0.33,return_sequences=True))(combined_model)\n",
    "# combined_model= Bidirectional(SimpleRNN(100,dropout=0.3))(combined_model)\n",
    "combined_model = Dropout(0.3)(combined_model)\n",
    "combined_model = Dense(1)(combined_model)\n",
    "model = Model(inputs=[ts_model.input,emb_model.input], outputs=combined_model)\n",
    "# model.compile(loss='mae', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cv = get_TS_cv()\n",
    "    df_forecast_error = pd.DataFrame(\n",
    "        columns=['h', 'mae', 'rmse', 'mape', 'descriptions'])\n",
    "    for train_idx, test_idx in cv.split(y):\n",
    "        # split train/test set for emb,X,y      \n",
    "        train_X = X[train_idx,:]\n",
    "        test_X = X[test_idx,:]\n",
    "        train_emb=emb[train_idx,:,:]\n",
    "        test_emb=emb[test_idx,:,:]\n",
    "        train_y = y[train_idx]\n",
    "        test_y = y[test_idx]\n",
    "\n",
    "        # normalize features\n",
    "        X_scaler = MinMaxScaler()\n",
    "        X_scaler.fit(train_X)\n",
    "        y_scaler = MinMaxScaler(feature_range=(1, 100))\n",
    "        y_scaler.fit(train_y)\n",
    "\n",
    "        train_X=X_scaler.transform(train_X)\n",
    "        test_X=X_scaler.transform(test_X)\n",
    "        train_y=y_scaler.transform(train_y)\n",
    "        test_y=y_scaler.transform(test_y)\n",
    "\n",
    "        # reshape to 3D for RNN/LSTM/GRU       \n",
    "        train_X=train_X.reshape(train_X.shape[0],step_size,train_X.shape[-1])\n",
    "        test_X=test_X.reshape(test_X.shape[0],step_size,test_X.shape[-1])\n",
    "        print(f\"train_X: {train_X.shape} test_X:{test_X.shape}\")\n",
    "        print(f\"train_y: {train_y.shape} test_y:{test_y.shape}\")\n",
    "\n",
    "        # model = Model(inputs=ts_inputs, outputs=ts_model)\n",
    "        # model = Model(inputs=emb_inputs, outputs=emb_model)\n",
    "        # model = Model(inputs=[ts_model.input,emb_model.input], outputs=combined_model)\n",
    "        # model.compile(loss='mae', optimizer=opt)\n",
    "        # model.compile(loss='msle', optimizer=Adam(0.0005))\n",
    "        # model.compile(loss='log_cosh', optimizer=Adam(0.0002))\n",
    "        # history = model.fit(x=train_X, y=train_y, epochs=80, batch_size=100, validation_data=(test_X, test_y), verbose=0, shuffle=False)\n",
    "        # history = model.fit(x=train_emb, y=train_y, epochs=80, batch_size=100, validation_data=(test_emb, test_y), verbose=0, shuffle=False)\n",
    "        history = model.fit(x=[train_X,train_emb], y=train_y, epochs=80, batch_size=40, validation_data=([test_X,test_emb], test_y), verbose=0, shuffle=False)\n",
    "        \n",
    "        # plot history\n",
    "        pyplot.plot(history.history['loss'], label='train')\n",
    "        pyplot.plot(history.history['val_loss'], label='test')\n",
    "        pyplot.legend()\n",
    "        pyplot.show()\n",
    "\n",
    "        # pred_y = model.predict(test_X)\n",
    "        # pred_y = model.predict(test_emb)\n",
    "        pred_y = model.predict([test_X,test_emb])\n",
    "        print(f\"pred_y: {pred_y.shape}\")\n",
    "\n",
    "        # scale\n",
    "        inverted_pred_y = y_scaler.inverse_transform(pred_y.reshape(test_y.shape))\n",
    "        inverted_test_y = y_scaler.inverse_transform(test_y)\n",
    "        original_test_price=df_original_price.to_numpy()[test_idx]\n",
    "        inverted_pred_y=inverted_pred_y+original_test_price\n",
    "        inverted_test_y=inverted_test_y+original_test_price\n",
    "\n",
    "        forecast_error = evaluate_series(inverted_test_y, inverted_pred_y, h)\n",
    "        # forecast_error = evaluate_series(test_y.reshape(-1, 1), pred_y.reshape(-1, 1), h)\n",
    "        print(forecast_error)\n",
    "        df_forecast_error = df_forecast_error.append(\n",
    "            pd.DataFrame(forecast_error), ignore_index=True)\n",
    "    mae = df_forecast_error[\"mae\"]\n",
    "    rmse = df_forecast_error[\"rmse\"]\n",
    "    mape = df_forecast_error[\"mape\"]\n",
    "    k = cv.get_n_splits()\n",
    "    msg = f\"\"\"\n",
    "    Forecast Error ({k}-fold cross-validation)\n",
    "    X: {X.shape}\n",
    "    y: {y.shape}\n",
    "    h= {h}\n",
    "    Model: {model.__class__.__name__}\n",
    "    MAE = {mae.mean():.6f} +/- {mae.std():.3f}\n",
    "    RMSE = {rmse.mean():.6f} +/- {rmse.std():.3f}\n",
    "    MAPE = {mape.mean():.6f} +/- {mape.std():.3f}\n",
    "    \"\"\"\n",
    "    print(msg)\n",
    "    logging.info(msg)\n",
    "    evaluation_result = {\n",
    "        'h': h,\n",
    "        'mae': [mae.mean()],\n",
    "        'rmse': [rmse.mean()],\n",
    "        'mape': [mape.mean()],\n",
    "        'descriptions': [msg]\n",
    "    }    \n",
    "except Exception as e:\n",
    "    logging.exception(\"EXCEPTION: %s\", e, exc_info=True)\n",
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-fold results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"multi,{df_forecast_error['mae'].to_numpy().mean()},{df_forecast_error['rmse'].to_numpy().mean()},{df_forecast_error['mape'].to_numpy().mean()}\")\n",
    "df_forecast_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_log=\"BiGRU;\"\n",
    "# FE_log=\"CLC1(h=1); 1stDIFF(xy)+ RFE(Ridge,60); scale y;\"\n",
    "# msg=f\"{model_log} {FE_log} mse;\"\n",
    "# evaluation_result[\"descriptions\"]=msg\n",
    "# df_result = pd.DataFrame(evaluation_result)\n",
    "# df_result[\"time\"] = datetime.datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "\n",
    "# df_result = df_result[['time', 'descriptions', 'h', 'mae', 'rmse', 'mape']]\n",
    "# df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_result.to_csv(f\"{HOME}/results/experiment_results.csv\",mode=\"a+\",index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8f3e05a59671f1eb5b3f5f0e003aaa5a39f5d3316373e39c3606e56079185283"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('OPP-env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
