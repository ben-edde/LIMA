{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_validate, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Reshape, MaxPool3D, Bidirectional, ConvLSTM2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import GRU\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Dropout\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "import pymongo\n",
    "import random\n",
    "import string\n",
    "import fasttext\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tag import pos_tag\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from textblob import TextBlob\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "HOME = os.environ['LIMA_HOME']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text: str) -> list:\n",
    "    \"\"\"\n",
    "    clean text with tokenization; stemming; removing stop word, punctuation, number, and empty string.\n",
    "\n",
    "    Args:\n",
    "        text (str): text\n",
    "\n",
    "    Returns:\n",
    "        list: cleaned text as list of tokenized str\n",
    "    \"\"\"\n",
    "\n",
    "    # to list of token\n",
    "    text = word_tokenize(text)\n",
    "\n",
    "    # stemming and convert to lower case if not proper noun: punctuation and stop word seem to help POS tagging, remove them after stemming\n",
    "    word_tag = pos_tag(text)\n",
    "    porter = PorterStemmer()\n",
    "    text = [\n",
    "        porter.stem(each[0])\n",
    "        if each[1] != \"NNP\" and each[1] != \"NNPS\" else each[0]\n",
    "        for each in word_tag\n",
    "    ]\n",
    "\n",
    "    # remove stop word: it seems stemming skip stop word; OK to remove stop word after stemming;\n",
    "    stop_word = set(stopwords.words('english'))\n",
    "    text = [each for each in text if not each in stop_word]\n",
    "\n",
    "    # remove punctuation\n",
    "    text = [\n",
    "        each.translate(str.maketrans('', '', string.punctuation))\n",
    "        for each in text\n",
    "    ]\n",
    "    # text = re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \" \", text) # if using re\n",
    "\n",
    "    # convert number to <NUM>\n",
    "    text = [\"<NUM>\" if each.isdigit() else each for each in text]\n",
    "\n",
    "    # remove empty string\n",
    "    text = [each for each in text if each != \"\"]\n",
    "\n",
    "    return text\n",
    "\n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = data.copy()\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "        \n",
    "\t\tnames += [f'{data.columns[j]}(t-{i})' for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [f'{data.columns[j]}(t)' for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [f'{data.columns[j]}(t+{i})' for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = pd.concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n",
    "\n",
    "def get_TS_cv(k=5, test_size=None):\n",
    "    \"\"\"\n",
    "    ML models do not need to care about forecast horizon when splitting training and test set. Forecast horizon should be handled by feature preparation ([X_t-1,X_t-2...]). Actually repeated K-fold can also be used, but stick to TS split to align with TS_evaluate().\n",
    "    \"\"\"\n",
    "    return TimeSeriesSplit(\n",
    "        n_splits=k,\n",
    "        gap=0,\n",
    "        test_size=test_size,\n",
    "    )\n",
    "\n",
    "def evaluate_series(y_true, y_pred, horizon):\n",
    "    \"\"\"\n",
    "    Some models (like ARIMA) may not support cross_validate(), compare the forecasting result directly\n",
    "    Args:\n",
    "        y_true: y of test set\n",
    "        y_pred: y of prediction\n",
    "        horizon: forecast horizon\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: single row DF with 3 metrics wrt horizon\n",
    "    \"\"\"\n",
    "    # RMSE\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    # MAE\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    # MAPE\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    r2=r2_score(y_true, y_pred)\n",
    "    forecast_error = {\n",
    "        'h': horizon,\n",
    "        'mae': [mae],\n",
    "        'rmse': [rmse],\n",
    "        'mape': [mape],\n",
    "        'r2':[r2],\n",
    "        'descriptions': \"\"\n",
    "    }\n",
    "    return forecast_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "seed_value = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "h = 1\n",
    "past = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from influxdb_client import InfluxDBClient\n",
    "client= InfluxDBClient.from_config_file(f\"{HOME}/dev/DB/influxdb_config.ini\")\n",
    "query_api = client.query_api()\n",
    "df_WTI = query_api.query_data_frame(\"\"\"\n",
    "from(bucket: \"dummy\")\n",
    "  |> range(start: 2011-04-01, stop: 2019-04-01)\n",
    "  |> filter(fn: (r) => r[\"_measurement\"] == \"WTI\") \n",
    "  |> filter(fn: (r) => r[\"type\"] == \"closing_price\") \n",
    "  |> pivot(rowKey:[\"_time\"], columnKey: [\"_field\"], valueColumn: \"_value\")\n",
    "  |> drop(columns: [\"_start\", \"_stop\"])\n",
    "\"\"\")\n",
    "df_WTI=df_WTI[[\"_time\",\"CLC4\",\"CLC3\",\"CLC2\",\"CLC1\"]]\n",
    "df_WTI.columns=[\"Date\",\"CLC4\",\"CLC3\",\"CLC2\",\"CLC1\"]\n",
    "df_WTI.set_index(\"Date\",inplace=True)\n",
    "df_WTI.index=df_WTI.index.map(lambda each: each.date())\n",
    "df_WTI.index=pd.to_datetime(df_WTI.index)\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month=[each.month for each in df_WTI.index]\n",
    "day=[each.day for each in df_WTI.index]\n",
    "day_in_week=[each.weekday() for each in df_WTI.index]\n",
    "df_dt=pd.DataFrame()\n",
    "df_dt[\"month\"]=month\n",
    "df_dt[\"day\"]=day\n",
    "df_dt[\"day_in_week\"]=day_in_week\n",
    "df_dt.index=df_WTI.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WTI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_model = fasttext.load_model(f\"{HOME}/data/big/cc.en.300.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentiment=pd.read_pickle(\"df_sentiment_2type.pkl\")\n",
    "df_sentiment.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic=pd.read_pickle(\"df_topic_2type.pkl\")\n",
    "df_topic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geoidx=pd.read_pickle(\"df_geoidx_2type.pkl\")\n",
    "df_geoidx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Xy = pd.concat([df_sentiment,df_topic, df_geoidx,df_WTI], axis=1, join=\"inner\")\n",
    "print(df_Xy.shape)\n",
    "df_Xy.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shifted = series_to_supervised(df_Xy.dropna(), past, h)\n",
    "# remove current day features for forecast\n",
    "for each in df_shifted.columns[:-1]:\n",
    "    if \"(t)\" in each:\n",
    "        df_shifted.drop(each, axis=1, inplace=True)\n",
    "# add time feature without shift \n",
    "df_shifted=pd.concat([df_dt,df_shifted],axis=1).dropna()\n",
    "raw_X = df_shifted.to_numpy()[:, :-1]\n",
    "y =  df_shifted.to_numpy()[:, -1].reshape(-1, 1) \n",
    "# y = df_Xy[df_Xy.index.isin(df_selected.index)].to_numpy()[:, -1].reshape(-1, 1)\n",
    "# y=df_WTI[df_WTI.index.isin(df_selected.index)][\"CLC1\"].to_numpy().reshape(-1, 1)\n",
    "f\"{raw_X.shape}   |{y.shape} | \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression,RFE,RFECV,SelectFromModel,SequentialFeatureSelector,chi2,SelectKBest,f_regression,VarianceThreshold,r_regression\n",
    "from sklearn.linear_model import Ridge,Lasso,LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor,ExtraTreeRegressor\n",
    "from sklearn.svm import LinearSVR,SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator = Lasso(random_state=42)\n",
    "# estimator = Ridge(random_state=42)\n",
    "estimator = LinearRegression( )\n",
    "# selector = RFECV(estimator,cv=get_TS_cv(),step=1)\n",
    "# selector = RFE(estimator,n_features_to_select=20,step=1)\n",
    "selector = SequentialFeatureSelector(estimator,n_features_to_select=20,cv=get_TS_cv())\n",
    "# selector=SelectFromModel(estimator,max_features=20)\n",
    "scaled_raw_X=MinMaxScaler().fit_transform(raw_X)\n",
    "selector = selector.fit(raw_X, y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = raw_X[:, selector.get_support()]\n",
    "print(f\"{X.shape} | {y.shape}\")\n",
    "df_shifted.columns[:-1][selector.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import LinearRegression, ARDRegression, SGDRegressor, ElasticNet, Lars, Lasso, GammaRegressor, TweedieRegressor, PoissonRegressor, Ridge, BayesianRidge\n",
    "from sklearn.ensemble import AdaBoostRegressor,RandomForestRegressor\n",
    "from keras.layers import Reshape,MaxPooling2D,Bidirectional,ConvLSTM2D\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import GRU\n",
    "from keras.layers import SimpleRNN \n",
    "from keras.layers import Conv2D,Conv3D,Conv1D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Input\n",
    "from keras.layers import Flatten\n",
    "from keras.models import Model\n",
    "from keras.layers.merge import concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "tf.keras.backend.clear_session()\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length=X.shape[0]\n",
    "train_size=int(length*0.7)\n",
    "step_size=1\n",
    "\n",
    "train_X=X[:train_size]\n",
    "train_y=y[:train_size,:]\n",
    "\n",
    "test_X=X[train_size:]\n",
    "test_y=y[train_size:,:]\n",
    "\n",
    "# X_scaler = MinMaxScaler()\n",
    "# X_scaler.fit(train_X)\n",
    "# train_X=X_scaler.transform(train_X)\n",
    "# test_X=X_scaler.transform(test_X)\n",
    "\n",
    "# train_X=train_X.reshape(train_X.shape[0],step_size,train_X.shape[-1])\n",
    "# test_X=test_X.reshape(test_X.shape[0],step_size,test_X.shape[-1])\n",
    "print(f\"train_X: {train_X.shape}\\t   \\t test_X:{test_X.shape}\")\n",
    "print(f\"train_y: {train_y.shape}\\t   test_y:{test_y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_X=np.concatenate([train_X,test_X])\n",
    "# lin_model=Lasso(random_state=42)\n",
    "# lin_model=Ridge(random_state=42)\n",
    "# lin_model=LinearSVR(random_state=42)\n",
    "# lin_model= SVR( )\n",
    "lin_model=LinearRegression()\n",
    "lin_model.fit(train_X,train_y.ravel())\n",
    "linear_y=lin_model.predict(all_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_series(y,linear_y,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_linear_y=y-linear_y.reshape(y.shape)\n",
    "non_linear_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nolds\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "rwalk = np.cumsum(np.random.random(y.shape[0]))\n",
    "nolds.lyap_r(rwalk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nolds.lyap_r(non_linear_y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nolds.hurst_rs(non_linear_y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "plt.plot(non_linear_y[250:300],'ob') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import STL\n",
    "\n",
    "stl = STL(non_linear_y, 21)\n",
    "res = stl.fit()\n",
    "decomposed_y=np.array([res.trend,res.seasonal,res.resid]).transpose()\n",
    "non_linear_y=decomposed_y\n",
    "fig = res.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler((1,100))\n",
    "X_scaler.fit(train_X)\n",
    "train_X=X_scaler.transform(train_X)\n",
    "test_X=X_scaler.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_non_linear_y=non_linear_y[:train_size,:]\n",
    "test_non_linear_y=non_linear_y[train_size:,:]\n",
    "f\"{non_linear_y.shape}|{train_non_linear_y.shape}|{test_non_linear_y.shape}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_linear_y_scaler = MinMaxScaler(feature_range=(1, 100))\n",
    "non_linear_y_scaler.fit(train_non_linear_y)\n",
    "train_non_linear_y=non_linear_y_scaler.transform(train_non_linear_y)\n",
    "test_non_linear_y=non_linear_y_scaler.transform(test_non_linear_y)\n",
    "f\"{train_non_linear_y.shape}|{test_non_linear_y.shape}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_out=train_non_linear_y.shape[-1]\n",
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 20)]              0         \n",
      "                                                                 \n",
      " reshape_10 (Reshape)        (None, 1, 1, 20, 1)       0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1, 1, 20, 3)       6         \n",
      "                                                                 \n",
      " reshape_11 (Reshape)        (None, 3, 20)             0         \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 100)              28400     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 3)                 303       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,709\n",
      "Trainable params: 28,709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ts_inputs = Input(shape=(train_X.shape[-1],))\n",
    "ts_model=Reshape((1,1,20,1))(ts_inputs)\n",
    "# ts_model=Reshape((step_size,train_X.shape[-1]))(ts_inputs)\n",
    "# ts_model=Reshape((1,1,1,20))(ts_model)\n",
    "# ts_model=ConvLSTM2D(1,(1,1),return_sequences=False)(ts_model)\n",
    "# ts_model= Dropout(0.2)(ts_model)\n",
    "# ts_model=ConvLSTM2D(50,(1,3),return_sequences=False)(ts_model)\n",
    "\n",
    "# ts_model= Dropout(0.4)(ts_model)\n",
    "# ts_model=Conv2D(1,(1,3) )(ts_model)\n",
    "# ts_model= Dropout(0.4)(ts_model)\n",
    "# ts_model=Conv2D(1,(1,3) )(ts_model)\n",
    "# ts_model= Dropout(0.4)(ts_model)\n",
    "ts_model=Dense(num_out)(ts_model)\n",
    "ts_model=Reshape((num_out,20))(ts_model)\n",
    "# ts_model=Bidirectional(GRU(50,dropout=0.2 ,return_sequences=True))(ts_model)\n",
    "# ts_model= Dropout(0.4)(ts_model)\n",
    "# ts_model=Bidirectional(LSTM(50,dropout=0.2 ,return_sequences=True))(ts_model)\n",
    "# ts_model= Dropout(0.4)(ts_model)\n",
    "ts_model=Bidirectional(LSTM(50,dropout=0.2 ,return_sequences=False))(ts_model)\n",
    "ts_model= Dropout(0.4)(ts_model)\n",
    "# ts_model= Dropout(0.4)(ts_model)\n",
    "# ts_model=Bidirectional(LSTM(500,dropout=0.1  ,return_sequences=True))(ts_model)\n",
    "# ts_model= Dropout(0.4)(ts_model)\n",
    "# ts_model=Bidirectional(LSTM(300,dropout=0.1  ,return_sequences=True))(ts_model)\n",
    "# ts_model= Dropout(0.4)(ts_model)\n",
    "# # ts_model=Bidirectional(GRU(300,dropout=0.2 ,return_sequences=True))(ts_model)\n",
    "# ts_model=Bidirectional(LSTM(100,dropout=0.1  ,return_sequences=False))(ts_model)\n",
    "\n",
    "# ts_model =Dense(50)(ts_model)\n",
    "# ts_model= Dropout(0.4)(ts_model)\n",
    "# ts_model =Dense(50)(ts_model)\n",
    "# ts_model= Dropout(0.4)(ts_model)\n",
    "\n",
    "\n",
    "ts_model= Flatten()(ts_model)\n",
    "ts_model =Dense(num_out)(ts_model)\n",
    "ts_model = Model(inputs=ts_inputs, outputs=ts_model)\n",
    "# ts_model.compile(loss='mae', optimizer=Adam())\n",
    "# ts_model.compile(loss='log_cosh', optimizer=Adam(0.0002))\n",
    "ts_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 20)]              0         \n",
      "                                                                 \n",
      " reshape_12 (Reshape)        (None, 2, 10, 1)          0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 2, 9, 20)          60        \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 2, 9, 20)          0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 1, 7, 1)           121       \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 1, 7, 1)           0         \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 7)                 0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 3)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 205\n",
      "Trainable params: 205\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# L_model=Dense(50,activation='linear')(ts_inputs)\n",
    "# L_model= Dropout(0.4)(L_model)\n",
    "# L_model=Dense(50,activation='linear')(L_model)\n",
    "# L_model= Dropout(0.4)(L_model)\n",
    "L_model=Reshape((2,10,1))(ts_inputs)\n",
    "L_model=Conv2D(20,(1,2))(L_model)\n",
    "L_model= Dropout(0.4)(L_model)\n",
    "# L_model=Conv2D(10,(1,3))(L_model)\n",
    "# L_model= Dropout(0.4)(L_model)\n",
    "# L_model=Conv2D(5,(1,3))(L_model)\n",
    "# L_model= Dropout(0.4)(L_model)\n",
    "# L_model=Conv2D(5,(1,3))(L_model)\n",
    "# L_model= Dropout(0.4)(L_model)\n",
    "L_model=Conv2D(1,(2,3))(L_model)\n",
    "L_model= Dropout(0.4)(L_model)\n",
    "# L_model=LSTM(20,dropout=0.2 ,activation='linear',return_sequences=True)(L_model)\n",
    "# L_model= Dropout(0.4)(L_model)\n",
    "# L_model=LSTM(20,dropout=0.2,activation='linear' ,return_sequences=True)(L_model)\n",
    "# L_model= Dropout(0.4)(L_model)\n",
    "# L_model=LSTM(20,dropout=0.2,activation='linear' ,return_sequences=False)(L_model)\n",
    "L_model= Flatten()(L_model)\n",
    "L_model=Dense(num_out)(L_model)\n",
    "L_model=Model(inputs=ts_inputs, outputs=L_model)\n",
    "L_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 3)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= concatenate([L_model.output,ts_model.output])\n",
    "model = Dense(num_out)(model)\n",
    "model = Model(inputs=[ ts_model.input ], outputs=model)\n",
    "model.compile(loss='log_cosh', optimizer=Adam(0.0002))\n",
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "36/36 [==============================] - 2s 17ms/step - loss: 41.9318 - val_loss: 19.4020\n",
      "Epoch 2/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 38.2523 - val_loss: 16.7446\n",
      "Epoch 3/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 37.0105 - val_loss: 17.1368\n",
      "Epoch 4/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 35.7991 - val_loss: 15.3007\n",
      "Epoch 5/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 34.8765 - val_loss: 15.2491\n",
      "Epoch 6/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 35.1581 - val_loss: 13.4991\n",
      "Epoch 7/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 32.6025 - val_loss: 14.2937\n",
      "Epoch 8/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 31.4232 - val_loss: 15.0937\n",
      "Epoch 9/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 30.7797 - val_loss: 12.9103\n",
      "Epoch 10/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 29.9792 - val_loss: 13.1936\n",
      "Epoch 11/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 29.6191 - val_loss: 13.6434\n",
      "Epoch 12/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 28.8637 - val_loss: 11.5975\n",
      "Epoch 13/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 27.9193 - val_loss: 13.8736\n",
      "Epoch 14/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 27.6745 - val_loss: 11.6715\n",
      "Epoch 15/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 26.5174 - val_loss: 11.5158\n",
      "Epoch 16/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 26.3130 - val_loss: 11.2543\n",
      "Epoch 17/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 26.0499 - val_loss: 12.8321\n",
      "Epoch 18/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 25.1083 - val_loss: 11.9226\n",
      "Epoch 19/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 24.3499 - val_loss: 10.7039\n",
      "Epoch 20/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 23.7439 - val_loss: 10.6330\n",
      "Epoch 21/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 23.4496 - val_loss: 11.2805\n",
      "Epoch 22/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 22.7753 - val_loss: 11.2277\n",
      "Epoch 23/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 22.3764 - val_loss: 10.0834\n",
      "Epoch 24/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 21.9029 - val_loss: 10.8592\n",
      "Epoch 25/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 21.6832 - val_loss: 11.1047\n",
      "Epoch 26/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 21.6116 - val_loss: 9.6293\n",
      "Epoch 27/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 20.6171 - val_loss: 10.2587\n",
      "Epoch 28/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 20.3168 - val_loss: 10.1162\n",
      "Epoch 29/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 20.3480 - val_loss: 9.9518\n",
      "Epoch 30/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 20.3167 - val_loss: 9.8662\n",
      "Epoch 31/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 19.5928 - val_loss: 10.6170\n",
      "Epoch 32/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 19.0955 - val_loss: 9.5643\n",
      "Epoch 33/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 19.0523 - val_loss: 9.5629\n",
      "Epoch 34/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 18.5388 - val_loss: 9.3030\n",
      "Epoch 35/100\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 18.1197 - val_loss: 9.9093\n",
      "Epoch 36/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 18.0174 - val_loss: 9.7380\n",
      "Epoch 37/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 17.2770 - val_loss: 9.3822\n",
      "Epoch 38/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 17.3680 - val_loss: 9.0559\n",
      "Epoch 39/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 17.1760 - val_loss: 8.9172\n",
      "Epoch 40/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 16.6241 - val_loss: 8.9023\n",
      "Epoch 41/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 16.7462 - val_loss: 8.5887\n",
      "Epoch 42/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 15.8470 - val_loss: 9.3149\n",
      "Epoch 43/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 16.0043 - val_loss: 8.5373\n",
      "Epoch 44/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 15.9157 - val_loss: 8.8377\n",
      "Epoch 45/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 15.5222 - val_loss: 8.9087\n",
      "Epoch 46/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 15.1408 - val_loss: 8.2400\n",
      "Epoch 47/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 15.3398 - val_loss: 8.7778\n",
      "Epoch 48/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 15.3097 - val_loss: 8.3360\n",
      "Epoch 49/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 14.9248 - val_loss: 8.5004\n",
      "Epoch 50/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 14.6827 - val_loss: 8.8439\n",
      "Epoch 51/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 14.4516 - val_loss: 8.0534\n",
      "Epoch 52/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 14.0705 - val_loss: 8.6197\n",
      "Epoch 53/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 13.9266 - val_loss: 8.0899\n",
      "Epoch 54/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 13.9992 - val_loss: 8.1956\n",
      "Epoch 55/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 13.8342 - val_loss: 8.0069\n",
      "Epoch 56/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 13.5554 - val_loss: 8.1758\n",
      "Epoch 57/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 13.3683 - val_loss: 7.8832\n",
      "Epoch 58/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 13.0254 - val_loss: 7.9161\n",
      "Epoch 59/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 13.0595 - val_loss: 8.0185\n",
      "Epoch 60/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 13.0548 - val_loss: 7.8404\n",
      "Epoch 61/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 12.8656 - val_loss: 7.6673\n",
      "Epoch 62/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 12.8900 - val_loss: 7.6852\n",
      "Epoch 63/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 12.7210 - val_loss: 7.6393\n",
      "Epoch 64/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 12.4344 - val_loss: 7.7190\n",
      "Epoch 65/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 12.3383 - val_loss: 7.5615\n",
      "Epoch 66/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 12.3379 - val_loss: 7.4795\n",
      "Epoch 67/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 12.1723 - val_loss: 7.7132\n",
      "Epoch 68/100\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 12.0198 - val_loss: 7.5215\n",
      "Epoch 69/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 12.1173 - val_loss: 7.4720\n",
      "Epoch 70/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 11.9630 - val_loss: 7.5829\n",
      "Epoch 71/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 11.7887 - val_loss: 7.5725\n",
      "Epoch 72/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 11.7112 - val_loss: 7.5097\n",
      "Epoch 73/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 11.6831 - val_loss: 7.4797\n",
      "Epoch 74/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 11.3912 - val_loss: 7.5244\n",
      "Epoch 75/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 11.2815 - val_loss: 7.3874\n",
      "Epoch 76/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 11.4815 - val_loss: 7.4655\n",
      "Epoch 77/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 11.5055 - val_loss: 7.4218\n",
      "Epoch 78/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 11.3687 - val_loss: 7.4197\n",
      "Epoch 79/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 11.2576 - val_loss: 7.4182\n",
      "Epoch 80/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 11.1108 - val_loss: 7.3544\n",
      "Epoch 81/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 11.1467 - val_loss: 7.2525\n",
      "Epoch 82/100\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 10.9654 - val_loss: 7.3887\n",
      "Epoch 83/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 10.9166 - val_loss: 7.3171\n",
      "Epoch 84/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 11.0147 - val_loss: 7.2908\n",
      "Epoch 85/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 10.8897 - val_loss: 7.3011\n",
      "Epoch 86/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 10.9034 - val_loss: 7.2736\n",
      "Epoch 87/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 10.9333 - val_loss: 7.3283\n",
      "Epoch 88/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 10.6975 - val_loss: 7.2961\n",
      "Epoch 89/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 10.6989 - val_loss: 7.3336\n",
      "Epoch 90/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 10.8275 - val_loss: 7.2270\n",
      "Epoch 91/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 10.6772 - val_loss: 7.2985\n",
      "Epoch 92/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 10.5693 - val_loss: 7.3001\n",
      "Epoch 93/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 10.6722 - val_loss: 7.2989\n",
      "Epoch 94/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 10.6119 - val_loss: 7.2728\n",
      "Epoch 95/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 10.5643 - val_loss: 7.2405\n",
      "Epoch 96/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 10.5216 - val_loss: 7.2647\n",
      "Epoch 97/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 10.5754 - val_loss: 7.2373\n",
      "Epoch 98/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 10.3740 - val_loss: 7.2578\n",
      "Epoch 99/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 10.6826 - val_loss: 7.2815\n",
      "Epoch 100/100\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 10.7042 - val_loss: 7.2309\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA0EklEQVR4nO3dd3zU9f3A8dcnl733DiRA2IEwFUEElCE4cBRHqTgqqPVXrfXnqtra/lqtta5WrKhU67aIe4EMEUEx7JFAGIEEyCYhe35+f3wOCJCQAHe53N37+Xgcufuue38gvO9zn+9nKK01QgghnI+HowMQQghxZiSBCyGEk5IELoQQTkoSuBBCOClJ4EII4aQ8O/PNIiMjdXJycme+pRBCOL21a9cWa62jTtzeqQk8OTmZjIyMznxLIYRwekqpva1tlyYUIYRwUpLAhRDCSUkCF0IIJ9WpbeBCCHG6GhoayMvLo7a21tGh2J2vry+JiYl4eXl16HhJ4EKILi0vL4+goCCSk5NRSjk6HLvRWlNSUkJeXh4pKSkdOkeaUIQQXVptbS0REREunbwBlFJERESc1jcNSeBCiC7P1ZP3EadbTqdI4EuzCpi7fKejwxBCiC7FKRL49ztL+MeSnTQ3y9zlQojOV1ZWxty5c0/7vKlTp1JWVmb7gKycIoEnRwZQ09BEQYXr34UWQnQ9bSXwpqamU573xRdfEBoaaqeonCSB94gMAGBPcZWDIxFCuKMHHniAXbt2kZ6ezogRIxg/fjzXX389aWlpAEyfPp1hw4YxYMAA5s2bd/S85ORkiouLycnJoV+/ftx6660MGDCASZMmUVNTc9ZxOUU3wuQWCfy8npEOjkYI4SiPfbqVbQcO2/Sa/eOD+f2lA055zBNPPMGWLVvYsGEDy5cvZ9q0aWzZsuVod7/58+cTHh5OTU0NI0aM4KqrriIiIuK4a2RnZ/POO+/w8ssvM2PGDD744ANmzpx5VrE7RQKPC/bFx9ODHKmBCyG6gJEjRx7XV/v555/nww8/BCA3N5fs7OyTEnhKSgrp6ekADBs2jJycnLOOwykSuIeHIiUyQJpQhHBz7dWUO0tAQMDR58uXL+ebb75h9erV+Pv7M27cuFb7cvv4+Bx9brFYbNKE4hRt4ADJEQHslgQuhHCAoKAgKioqWt1XXl5OWFgY/v7+ZGVl8cMPP3RaXE5RAwdIiQpgSVYBjU3NeFqc5nNHCOECIiIiGD16NAMHDsTPz4+YmJij+6ZMmcK//vUvBg0aRJ8+fTj33HM7La4OJ3CllAXIAPZrrS9RSoUD7wHJQA4wQ2t9yB5BAqREBNDQpNlfVkP3iID2TxBCCBt6++23W93u4+PDl19+2eq+I+3ckZGRbNmy5ej2e++91yYxnU5V9i4gs8XrB4AlWutUYIn1td2kRElXQiGEaKlDCVwplQhMA15psfly4HXr89eB6TaN7ATJEZLAhRCipY7WwJ8F7gOaW2yL0VofBLD+jG7tRKXUbKVUhlIqo6io6IwDjQz0JsjHU7oSCiGEVbsJXCl1CVCotV57Jm+gtZ6ntR6utR4eFXXSosodppQiOVJ6ogghxBEduYk5GrhMKTUV8AWClVJvAgVKqTit9UGlVBxQaM9AAVIiA1ifa7f7pEII4VTarYFrrR/UWidqrZOBa4GlWuuZwCfALOths4CP7RalVUpkAPsP1VDXeOoJZIQQwh2cTYfqJ4CJSqlsYKL1tV2lRAbQrCG3tNrebyWEEEed6XSyAM8++yzV1fbJWaeVwLXWy7XWl1ifl2itL9Rap1p/ltolwhZSrJNa7S6SdnAhROfpqgncaUZiwvGzEgohRGdpOZ3sxIkTiY6O5v3336euro4rrriCxx57jKqqKmbMmEFeXh5NTU088sgjFBQUcODAAcaPH09kZCTLli2zaVxOlcBD/LyICPAmp0QSuBBu6csHIH+zba8ZmwYXn7oFuOV0sosWLWLBggWsWbMGrTWXXXYZK1asoKioiPj4eD7//HPAzJESEhLC008/zbJly4iMtP1U2E43qUhyZIA0oQghHGbRokUsWrSIIUOGMHToULKyssjOziYtLY1vvvmG+++/n++++46QkBC7x+JUNXAw7eArdpz5gCAhhBNrp6bcGbTWPPjgg8yZM+ekfWvXruWLL77gwQcfZNKkSTz66KN2jcXpauBpCSEUVtSxZX+5o0MRQriJltPJTp48mfnz51NZWQnA/v37KSws5MCBA/j7+zNz5kzuvfde1q1bd9K5tuZ0CXz6kAT8vS38+/scR4cihHATLaeTXbx4Mddffz2jRo0iLS2Nq6++moqKCjZv3szIkSNJT0/nz3/+Mw8//DAAs2fP5uKLL2b8+PE2j0tprW1+0bYMHz5cZ2RknPV1HvloC+/9lMv3D0wgKsin/ROEEE4rMzOTfv36OTqMTtNaeZVSa7XWw0881ulq4AA3jk6mvqmZt3/c5+hQhBDCYZwygfeMCmRcnyje+GGvDKsXQrgtp0zgADeNTqG4so7PNx10dChCCDvrzKZeRzrdcjptAh+bGknPqADmf7/Hbf5xhXBHvr6+lJSUuPz/c601JSUl+Pr6dvgcp+sHfoRSiptGp/DwR1v4KecQI1PCHR2SEMIOEhMTycvL42wWhHEWvr6+JCYmdvh4p03gAFcNTeSpRdt55bvdksCFcFFeXl6kpKQ4OowuyWmbUAD8vC3MPKc7izMLZKk1IYTbceoEDnDDqO54eij+/f0eR4cihBCdyukTeHSwL5cNTuD9jDzKqxscHY4QQnQap0/gALeMSaGmoYm318jAHiGE+3CJBN4/PpjRvSJ4bdUe6hubHR2OEEJ0CpdI4ABzxvak4HAdr6/KcXQoQgjRKVwmgY/tHcX4PlE8tySbwopaR4cjhBB2124CV0r5KqXWKKU2KqW2KqUes27/g1Jqv1Jqg/Ux1f7hntojl/SnrrGJJ7/a7uhQhBDC7jpSA68DJmitBwPpwBSl1LnWfc9ordOtjy/sFWRH9YgK5OYxKSxYm8f6fYeoqmvkn0uzmfzMCnYXVTo6PCGEsKl2R2JqMwHBkeznZX102UkJ/mdCKgvX7ec3722goraRkqp6AJZmFdIjKtDB0QkhhO10qA1cKWVRSm0ACoHFWusfrbvuVEptUkrNV0qFtXHubKVUhlIqozPmMgj08eR3U/uRU1JN37ggFt5xHgmhfmzILbP7ewshRGc6rRV5lFKhwIfA/wBFQDGmNv4nIE5rffOpzrfVijwdUVhRS3SQmdXrV2+tY2NeGSvvn9Ap7y2EELZkkxV5tNZlwHJgita6QGvdpLVuBl4GRtoiUFs5krwBBieFkHeohuLKOgdGJIQQttWRXihR1po3Sik/4CIgSykV1+KwK4AtdonQBgYnhgKwKa/MoXEIIYQtdWQ62TjgdaWUBZPw39daf6aUekMplY5pQskB5tgtyrM0MCEEDwUbcsuZ0DfG0eEIIYRNdKQXyiZgSCvbf2GXiOwgwMeT3jFBbJQbmUIIF+IyIzHbMzgxlI15ZS6/LJMQwn24TwJPCqWsuoF9pdWODkUIIWzCjRJ4CID0BxdCuAy3SeB9YoLw9fJgY265o0MRQgibcJsE7mnxIC0hhI3SlVAI4SLcJoGDuZG5ZX85DU2y6IMQwvm5VwJPCqWusZnt+RWODkUIIc6aWyXwod3NfFuLtxU4OBIhhDh7bpXAE0L9mNA3mjd+2EtNfZOjwxFCiLPiVgkcYM7YHpRW1bNgXZ6jQxFCiLPidgl8ZEo4g5NCeeW73TQ1y6hMIYTzcrsErpRiztge7C2pZtHWfEeHI4QQZ8ztEjjA5AGxdI/w56UVu2VuFCGE03LLBG7xUPxyTAobcstYvavE0eEIIcQZccsEDnD1sCQSw/y4+70NHCyvcXQ4Qghx2tw2gft5W3hl1nCq6hq59T8ZVNc3OjokIYQ4LW6bwAH6xgbzj+uHsO3AYe55byPN0itFCOFE3DqBA0zoG8NDU/vx1dZ8Xli209HhCCFEh7l9Age4ZUwKlw2O57kl2Ww9INPNCiGcQ0dWpfdVSq1RSm1USm1VSj1m3R6ulFqslMq2/gyzf7j2oZTiscsGEBbgzW/f30h9o8xWKITo+jpSA68DJmitBwPpwBSl1LnAA8ASrXUqsMT62mmFBXjz+BVpZOVX8I+l2Y4ORwgh2tVuAtdGpfWll/WhgcuB163bXwem2yPAznRR/xiuGprI3OW7WLv3kKPDEUKIU+pQG7hSyqKU2gAUAou11j8CMVrrgwDWn9FtnDtbKZWhlMooKiqyUdj28+il/YkN9uW6eT/wwrKdNMriD0KILqpDCVxr3aS1TgcSgZFKqYEdfQOt9Tyt9XCt9fCoqKgzDLPzhPh58fGdo7mwXzR/+3o7V724il1Fle2fKIQQney0eqForcuA5cAUoEApFQdg/Vlo6+AcJTLQhxdnDuOF64eyr7SaWfPXcLi2wdFhCSHEcTrSCyVKKRVqfe4HXARkAZ8As6yHzQI+tlOMDjNtUByvzBrBwfJaHv1oi6PDEUKI43SkBh4HLFNKbQJ+wrSBfwY8AUxUSmUDE62vXc6w7mH8ekIqH204wEfr9zs6HCGEOMqzvQO01puAIa1sLwEutEdQXc2vxvfku+wiHvloC8O6h5EU7u/okIQQQkZidoSnxYNnrkkH4L4Fm2QOcSFElyAJvIOSwv257+K+rN5dwteyko8QoguQBH4arhuRRJ+YIP78RSZ1jbKqvRDCsSSBnwZPiwcPX9KP3NIa/v19jqPDEUK4OUngp+n81Cgu6hfNP5fupKiiztHhCCHcmCTwM/DQ1H7UNTZx34KN5JZWOzocIYSbkgR+BnpEBfK/k/uwcmcxF/xtGb96ex1Z+YcdHZYQws1IAj9Ds8f25Lv7JjB7bE9W7Chixr9WUyHD7YUQnUgS+FmIDfHlgYv78tYvz+FwbSPvrNnn6JCEEG5EErgNDEoM5byeEby6co90LxRCdBpJ4DZy2wU9KThcJ/OlCCE6jSRwGzk/NZIB8cG8tGI3Tc0y1F4IYX+SwG1EKcVtF/Rkd1EVi7fJUHshhP1JArehiwfG0j3Cn6cW7WDFjiKpiQsh7EoSuA15Wjx4ZFp/iivruGH+Gsb8dSlPL9pOSaWM2BRC2J7qzKlRhw8frjMyMjrt/RylrrGJb7YV8t+1uXy7owhfTws/P6cbs8f2IDrY19HhCSGcjFJqrdZ6+EnbJYHb187CSuYu28nHGw/g52Xh81+PoXtEgKPDEkI4kbYSuDSh2Fmv6ECeviadr+8eS7PWPP5FlqNDEkK4CEngnaRXdCB3jOvJV1vzWb2rxNHhCCFcgCTwTvTL83uQEOrHHz/bJj1UhBBnrd0ErpRKUkotU0plKqW2KqXusm7/g1Jqv1Jqg/Ux1f7hOjdfLwsPTe1H5sHDvPdTrqPDEUI4uY7UwBuB32qt+wHnAr9SSvW37ntGa51ufXxhtyhdyNS0WEYmh/P3Rdspr5bZC4UQZ67dBK61Pqi1Xmd9XgFkAgn2DsxVKaV49NL+lNc08NCHm2WFeyHEGTutNnClVDIwBPjRuulOpdQmpdR8pVRYG+fMVkplKKUyioqKzi5aFzEwIYTfTOzN55sP8sE6mfxKCHFmOpzAlVKBwAfA3Vrrw8CLQE8gHTgI/L2187TW87TWw7XWw6Oios4+Yhdx2wU9OSclnN9/vIW9JVWODkcI4YQ6lMCVUl6Y5P2W1nohgNa6QGvdpLVuBl4GRtovTNdj8VA8c006Fg/FXe9uoKGp2dEhCSGcTEd6oSjgVSBTa/10i+1xLQ67Athi+/BcW3yoH3+5Mo0NuWU8/OEWaQ8XQpwWzw4cMxr4BbBZKbXBuu0h4DqlVDqggRxgjh3ic3mXDIpne34F/1i6k9gQX34zsbejQxJCOIl2E7jWeiWgWtkl3QZt5J6Jvckvr+W5JdnEhvhy3chujg5JCOEEOlIDF3amlOIvV6ZRVFnH7z7cTN6hauZc0JNgXy9HhyaE6MJkKH0X4WXx4IXrh3LZ4HheWLaLcX9bzr+/30Oj3NwUQrRBEngXEuDjybPXDuHTO8fQJyaIxz7dxsMfyc1NIUTrJIF3QWmJIbx96zncMa4n7/6Uy9tr9jk6JCFEFyQJvItSSvHbSX0Y1yeKP3yylYycUkeHJIToYiSBd2EWD8Vz1w4hIdSP299ax4GyGkeHJIToQiSBd3Ehfl7Mu2E4NfVNXPqPlXy7Q+aTEUIYksCdQO+YID684zwiA32YNX8Nj3+ZKUPvhRCSwJ1FakwQH985mutGduOlb3dzw6trKK+R+cSFcGeSwJ2Ir5eFx69M4+8/G8xPOaX87F+rpF1cCDcmCdwJXTUskddvHsnBslqumPs9q3YVS19xIdyQJHAnNbpXJP+9fRQWpbj+5R+Z/OwKXl+Vw4GyGpplwWQh3ILqzJrb8OHDdUZGRqe9nzuorm/k040HeOvHfWzKKwfA2+JBYrgf145IYvbYng6OUAhxtpRSa7XWw0/cLpNZOTl/b0+uGdGNa0Z0Y8v+cjbmlbGvtJqf9pTy+JdZjO0dRd/YYEeHKYSwA0ngLmRgQggDE0IAOFRVz9i/LePJr7Yz/8YRDo5MCGEP0gbuosICvLljXC+WZhXyw+4SR4cjhLADSeAu7KbRycSF+PL4l1nSS0UIFyQJ3IX5eln4zcTebMwt44vN+Y4ORwhhY5LAXdxVQxPpHRPIgws38erKPdQ3yhB8IVxFu90IlVJJwH+AWKAZmKe1fk4pFQ68ByRjFjWeobU+dKprSTdCx9hdVMmjH29l5c5iukf48/NzutHQpKmsa6S+sZlAH0+CfD3pGR3I+D7Rjg5XCHGCtroRdiSBxwFxWut1SqkgYC0wHbgRKNVaP6GUegAI01rff6prSQJ3HK01y3cU8ZfPM8kurATAy6LwsnhQXd909Li//2wwVw1LdFSYQohWnHE/cK31QeCg9XmFUioTSAAuB8ZZD3sdWA6cMoELx1FKMb5PNBekRlFaXU+gjyc+nh4opWhq1lTUNjDnjbU8/NEWBieF0is60NEhCyHacVpt4EqpZGAI8CMQY03uR5J8q9+9lVKzlVIZSqmMoiKZy9rRPDwUkYE++HpZUEoBZuGIUH9vnrt2CH7eFu58ex21DU3tXEkI4WgdTuBKqUDgA+BurfXhjp6ntZ6ntR6utR4eFRV1JjGKThIb4svTMwaTlV/BY59udXQ4Qoh2dCiBK6W8MMn7La31QuvmAmv7+JF28kL7hAjUHIKDG+12eXHMuD7R3D6uJ++syeXJr6T/uBBdWbsJXJnv2a8CmVrrp1vs+gSYZX0+C/jY9uFZLXoY3rgCJJl0insn9eH6c7oxd/kuHvpwM00yu6EQXVJH5kIZDfwC2KyU2mDd9hDwBPC+UuoWYB/wM7tECBA/BNa/CeW5ENrNbm8jDIuH4s/TBxLu780/l+2kuLKeaWlxhAV4ExvsS++YwKPt50IIx+lIL5SVQFv/Wy+0bThtiB9ifh5YLwm8kyiluHdyH0L9vXj8yywWbys4uu/G85J59JL+eHhIEhfCkZxjNsKYgeDhZRJ4/8sdHY1b+eX5PZgxIoniijpKq+r5ZOMBXluVQ3V9I49fOQiLJHEhHMY5ErinD8T0NwlcdLpgXy+Cfb3oEQXDuocR6u/N80uyqa5v4ukZ6Xh7yowMQjiCcyRwMM0oWz80NzKl/dVhlFLcM7E3Ad4WHv8yi/zyWl74+VBign0dHZoQbsd5qk7xQ6C2HA7tcXQkAphzQU+ev24I2w4eZtrzK2XOcSEcwLlq4GCaUcJ7ODYWAcBlg+PpGxvEbW+u5eev/Mg5KeH0jwtmQEIwkwfE4u/tPL9eQjgj56mBR/UDi4+0g3cxvWOC+OTOMdx0XjJVdY288cNefvPeRua8sZZm6T8uhF05TxXJ0xtiB8KBDY6ORJwg0MeThy/pD0BjUzNv/rCXP3y6jXnf7ea2C3o6ODohXJfz1MDBNKMc2ADNsihBV+Vp8WDWeclMTYvlqa+3s37fKaeIF0KcBedL4PUVULrL0ZGIU1BK8fgVg4gJ9uXX765n7d5SFqzN4/EvM5m/cg+FFbWODlEIl+A8TShw/I3MyFRoqIHDByBCvqZ3NSH+Xjx/XTozXvqBq15cDZgFJBqaNP/3+TZG94pkztiejEmNdHCkQjgv50rgkX3A088k8JgBsOBmKNkFd22EkARHRydOMKx7OG/cPJLymgZ6xwbRPdyfnJIqPt5wgIXr9nPjv9fwws+HMnlArKNDFcIptbukmi3ZZEm1VyfBoRzTJ9zTF2rL4JJnYfhNNohQdJaK2gZ+8eoath4o518zh3FhvxjALP2mNTLPihAttLWkmnO1gQPED4XKAkgeA3f+ZCa3yl7k6KjEaQry9eL1m0fSNzaY299cx+NfZHLzaz8x5E+LueiZb2VFICE6wPkS+Pm/hWvfhuv/C4HRkDoZdi+HBrkx5mxC/Lx445aRpMYE8tKK3ewrrWZMr0h2F1Xx4nK5US1Ee5yrDRwgMAr6Tjv2uvcU+OllyFkJqRc5Li5xRkL9vfn0zjFU1jcS7OsFgIdaz4vf7uKqoYl0i/B3cIRCdF3OVwM/UfIY8PKH7K8dHYk4Qx4e6mjyBvjdtH54eShZl1OIdjhfDfxEXr6QcgHs+AouflJmKnQBMcG+3H1Rb/78RSYfrd+PxUOxbHshu4qqSInwJzUmiLSEEM5PjZSVgYRbc/4EDtB7Euz4Eoq2Q3RfR0cjbODG0cm8n5HL3e9tACDU34u+sUH8lHOIjzYcAGDKgFieuCqNUH9vB0YqhOO4RgJPnWR+Zn8tCdxFeFk8+Mf1Q1i0tYDRvSJITwo7uvpPZV0jb/+4lye/2s7U58p47rohjEgOd3DEQnS+jqxKP18pVaiU2tJi2x+UUvuVUhusj6n2DbMdIYkQkwY7pB3clfSNDebXF6YyrHv4cUu3Bfp4MntsTz64/Ty8PD245qXVPL14B41Nx8+R09DULDMiCpfW7kAepdRYoBL4j9Z6oHXbH4BKrfVTp/NmNhnI05Ylf4SVz0CPcRAYC2HJMOZusxybcFkVtQ38/pOtLFy3n/SkUJ68ehC7Civ5YN1+lm8vpElrAr09CfH34sbzkrl5dIoMEhJOp62BPB1ZlX6FUirZLlHZ0tAboHgHlO+HwkyoOGjmSxl4ZevHNzXCt0/AoGshslfnxipsJsjXi6dnpDOhbzQPLdzMpGdWABAd5MMNo5IJ9LFwuLaRHQUV/N/nmXy7o4infjZYloATLuFs2sDvVErdAGQAv9VaO3be0LBkuOZN87y5CZ5Khe1ftJ3AVz4DK/4G9VUw5fFOC1PYxyWD4hnaLYz3M3IZ2i2M0b0ij2t20Vrzzppc/vjZVqY8u4J7Jvbm6mFJ+HlbHBi1EGenQ3OhWGvgn7VoQokBigEN/AmI01rf3Ma5s4HZAN26dRu2d+9e20Teno/ugKzP4H93gcXr+H35m2HeeGhugNhBcNt3nROTcLidhZXc/8Em1u49RKi/FzPP6c4No7oTLTVy0YXZdC4UrXWB1rpJa90MvAyMPMWx87TWw7XWw6Oios7k7c5Mn6lmwqu93x+/vbEePrwd/MJg5ByTzGvKOi8u4VC9ogNZcNso/nvbKEYmh/PC8p2c98RS7np3vSw+IZzOGSVwpVRci5dXAFvaOtZheo43sxVmfXH89hV/g4LNcOlz0O9SQMO+1Q4JUTiGUooRyeHMu2E4y347jhtGJbM0s5Ar5q5i1vw1FB6WeXWEc+hIN8J3gNVAH6VUnlLqFuBJpdRmpdQmYDzwGzvHefq8A6DHeNMOfqSZ6MB6+O7vMPg66DsVEkeYhZJzVjo2VuEwyZEBPHppf1Y/dCG/m9qPH/eUMPnZFXy9Nd/RoQnRro70Qrmulc2v2iEW2+s71YzQzN8Mkb3hw9sgMObYTUsvX0gcfnIzi3A7gT6e3Dq2B+P7RnHXuxuY88ZaxvaOYlzvKMakRhIT5Mu+0mr2lVbjaVGM7hVJoI9rjIMTzsu1fwN7TwGUqYVv/i8UZcHMD0z79xHdR8N3T5n2ct+Qjl8781OoLoVhs2wetnCcXtFBfHjHaF5YtpOPN+znj58VtXqct8WD83pFMC0tjulDEvCyOP+8cML5ON+KPKfr1UlwaK9ZBGLYjXDps8fv3/0t/OcyM79470knn1+w1ST84Pjjt784Gspz4b494CFd0VxVbmk1q3YVc7imkaRwf7pH+FNW3cCSzAIWZxawt6SabuH+3H1RKpenJxzXdVEIWznjgTxOr89U+Ob3ENodJv3p5P2JI8DDC/auPD6Baw0//gu+fgh6XggzFxzbV1NmEjva/IwbZO9SCAdJCvfnmvBuJ20f1TOC303rx/LtRTy1aDv3vL+R55dkM31IApcNjqdHVKADohXuxvW/9w280rR/X/ES+ASdvN/bHxKGQU6LdvDGevj0LvjqAfAOMjc5G+uO7c9dg+kCD+xdZdfwRdellGJ832g+vXMMc38+lNgQX55bks2Ev3/L5S98zzrplijszPUTeGg3s3Zm91FtH5M82vRQqauA3J/gtWmw7nWzfNv0udBYY03aVvtWgYcnBMWbmrtwax4eiqlpcbw7exSrH7iQh6f1o/BwLVe9uIpHP95CRW0DAM3Nmsq6RqrqGqmpb6K+sbmdKwtxaq7fhNIRyWNM98LXpsHBjeAfCVe9CmlXm5ubygJ7voWU883xe1dD/BCISDVT2GotC0kIAGJDfPnl+T24dmQ3nvp6O6+vzmHhuv14KKioa6TlLSel4NyUCC5Lj+figbGE+HlR29BMbUMTof5esliFaJfr38TsiPoq+Fsv0xY++n/gnNvBp0Ub5ivWtTZ/+Y1ZPPmJJDhnDkT1hY9/BXf8ANH9Tv0eBVth5bNwyTPHX1u4tPX7DvF+Ri4+nhaCfT0J8PFEKWjWUFbdwKKt+ewursJDmUa5I/8dE0L9mNg/hkkDYjgnJUJujro5972J2RHeAXDbSvAPP76L4RE9xsF3T5vaeMFWaKqHbucdWzwiZ2X7CfyHubD5fdObZeJjNi+C6JqGdAtjSLdWfqes7p/Shy37D/NNZgFaa/x9PPH0UPywu5R31uzjtVU5pEYHcu/kPkzqHyO1cnEcSeBHRPRse1/KBWYIfs73ULjNbOt2rkn2QfHmRubIW9s+v7He9Bv38ILVL8CQmWaqW+H2lFKkJYaQlnj8GIRfnt+D6vpGFm8r4Lkl2cx5Yy3pSaFcMyKJvrFB9IkNwt9b/vu6O/kN6IikkeDpB7uXQ+kuiOpnautgboDuWXHqdvBdS03t/fIX4KsH4cv7YOZCaTcXp+Tv7cnl6QlMS4tj4br9PPvNDh5cuBkwvzoBLRJ4QqgfF/aLZmL/GAYnhsqiFW5CEnhHePqYXiy7lpoBQWlXH9vX/TwzyrNkV9sLQ2xdCL6hkDbD9HT56gHI+hz6XdIp4Qvn5mnxYMaIJK4elkjeoRoy8w+zPb+C8hrTu0VryDx4mJdW7Gbu8l1EBnozNjWKC/pEkRTuz478CrLyK6isa2R0rwjGpkYRESgrVbkCSeAd1WMcLH7UPO/Wokti9zHm596VrSfwhhqTrAdeCZ7eMOJWWPcfUxPvdSF4+dk9dOEaPDwU3SL86Rbhz+QBsSftL69uYNn2wqOPhev3H90X4G3By9ODBWvzUAoGJ4YyeUAsFw+MJTkyoDOLIWxIEnhHpVxw7HnLBB6ZCgHRpn182I0nn5e9COorYYB1ZSCLJ0z+C7wxHTa+C8NvsmfUwo2E+HsxfUgC04ck0NSs2ZRXRlFFHX1jg0kMMxWFzfvLWb69iG8yC/jrV1n89assekUH0jsmkOSIALpH+BPs60WAjyfhAd4MiA+WG6ddmCTwjoodZG5aegdCaNKx7UpBylhrM8pOSJ1kmkZi08z+LQshIAqSzz92To9xEDcYfngRhs4CD9cfTyU6l8VDtdr7ZXBSKIOTQrnrolTyDlXz1ZZ8vt9ZTObBChZtLaCx+fhuxYMTQ3jg4n6M6hnR6vvUNjRRVt1AdX0j1fVNJIX5E+Lv1eqxwvakH/jp+PElszzb8BNWj6sqgYz5prad9xOgoecEGPUreHem6XUy7anjz9n4Hnw4G36+AFIndloRhGhLQ1Mz+eW1R0eL7iio5J9LszlQXssFvaOYmhZLWkIoPaICWL27hAVr81i8reC4EaVKQf+4YEb1iGB4chiDEkOJC/GVWvxZaqsfuCRwW6sqgfVvwOp/QpV1KtKbvjQ3O1tqrIdn00z/8Rs+Ovk6pXvg/RugoRoCY03/8Qvub/tGqRB2UNvQxH9W5/Cvb3dTWlUPmCStNYT5e3Hp4Hj6xgbj723Bx9ODHQWVrN5dzLp9ZUcTe2SgD8O7h3F+70jO7xVFUrgfFXWNlFc3EOjjSViAtyOL6BQkgXe2+mozn8qhHJj8eOvNJN/9HZb8EW5fBTEDjm2vPQyvToSKfNPcUlkABzeZxSdmfXLydZoaIfMTWDPPTAsw4WF7lUq4qeZmzd7SajbllbE9v4JBiaFM6BuNt2frzX+1DU1kHjzMprxyNuaV8ePuUvaX1QDgYR2JeuT5uT0imDYojgt6RxET7Ht0bvXiyjoyDx6muLKOgfEh9IwKdNvukZLAu6LqUni6P6RdZfqIAzQ3wTvXmi6LMxdCD+vN0++fM71gbl1qZk88YtP7sPT/oGwvWLzNYKH/zTajS4XoIrTW7C6uYmV2MUUVdYT4eRHi50XuoWo+33SQ3cVVR48N9ffCohQl1hp/y+0D4oPxUIq6xmbqG5upqmuksq6R+sZmJvaP4abRKfSJPXnW0fLqBjbklREb7EvvmECna9KRBN5VfXaPaXI5738gLBn2r4W1r5k5U1q2tddVwDMDzM3Qa98y2/augn9Phfh0OP9e8As1E3JdMQ8GX3N2cdVXm6l2hbAzrTVZ+RWs3XuI4so6iivraGjUpMYE0j8umIhAHzbmlpGxt5Tt+RV4eCi8LR54e3oQ6ONJoI8n9U3NfL01n9qGZkb1iKB7hD9aQ0NzM9sOHGZ7QcXReWZig305PzWSkSnhpCWG0CsqkGYN2YUVbDtwmNrGZuJDfIkN8SU22JdQf+/Tnosm71A1C9bmUV7TQG1DEzX1Tdw2rid9Y4PP6O9I5kLpqkbfBbk/momudJPZNnLOyTdKfYJg5GwzpL9oOwTFwYdzTNKf9ZmZIKu52SxcsfGds0vgq+eapp1bvja9ZYSwI6UU/eKC6RfXdnLrExvEjBFJbe4HOFRVzzs/7WPB2jx2F1cC4KEUvaIDmZoWx7DuYeQdqmbFjmK+3prPf9fmAeDj6UGz1jQ0tV6Z9VAQHuBDZKA3Yf7ehAd6423xoKiijoLDtTRrzcUD47hqWCLRQT68uHwX877bTUNTM4Henvh6W/DzsnCoquEM/4ba1m4NXCk1H7gEKNRaD7RuCwfeA5KBHGCG1rrd2eulBn4KTY1wOM+s9hM7qPU286pieGagGRSEgo1vw81fm6H+Ryz7C3z7JNyz7dgycE2N0NzQsUFDB9bDKxPN8b2nwPXv2aJ0QnQpTc2aPcVVbNlfzpb95VgsigHxIQyIDybQx5MDZTXkl9dScLiW4sp6SqrqKK6s51BVPaXV9dQ1NBMd7EN0kA9VdU2s2lVMszaLY1fWNTI9PZ77pvQlPtQ2A/XOuAlFKTUWqAT+0yKBPwmUaq2fUEo9AIRpre9vLwhJ4DbwxX3w08ugm02zyYWPHL+/ZBf8Yyhc9BiMudv0dnnratj7vVk+rsc46DHe3BA9cS3Pukp4aawZPTrwStOT5pdLzLFCiDbll9fy4fr9ZOUfZtZ5yQw9xQyUZ+Ks2sCVUsnAZy0S+HZgnNb6oFIqDliute7T3nUkgdtAWS48n256rdzyjRmef6JXJpo28ztWm/nKN7wFg6+HoixTw0abRSt6T4FeEyC6P4T3hM/vgfVvmp4u8UPhuUHm20Br3RxPVFcJXv4yKEkIO7B1G3iM1voggDWJR5/ijWcDswG6dTt5cVhxmkKTzMISId1aT94Ag681yfjDObDpPdN/fPxDZl91KexeBtu/hKxPYcObZruymDb4MfeYkaUAo++GxY+Ym6Un9mNvKXcN/Ody8A2BvtOg36XmZuuJNXwhhE2daQ28TGsd2mL/Ia11u98ZpAbeSapL4e99zMITaT+DK19uferapgazQEVxNhRvN8dPeMSMNgXTE+X5dFM7v/yfZpunDwQnHLtecbbps+4bar4V7Fxi1hCNH2q6Rsb074wSC+HSbF0DL1BKxbVoQik8u/CETfmHm14sZftMEm2rz6vFy3RBjE9vfb+3v1nY+cv7TLv6EUnnwtj/hdiB8OaVZoHnXyyE8B4m6W/7GBY9bNrTL7jftMVbZH4MIWztTGvgfwNKWtzEDNda39fedaQG7oSam8x0uI215nVFvpkT5nCeafNGwY2fQcLQ48+rKjaJf8sHpo196lNm8YvTsWsZ7FpibshKc4xwY2fTC+UdYBwQCRQAvwc+At4HugH7gJ9prUvbC0ISuItorDdt6xveMjXxXhe2fWzWF/Dl/VC+DwZdC+PuNzX19pTuMTX4usMw8Y+mv7wQbkpGYgrHqa+G756C7583/ctDu5kbpVF9weJjbsbGDDzWXbGxDuZPhtLdpi197/dw6zLTZNPymmX7zFwzzQ3QZ+qZ1dKP/P472dBq4V4kgQvHO7QXdnwNe76FnJVQW3b8/v7TYdKfzDzpP8yFa94yi2fMPdfMqT57GVQWwtI/mTlgaPG7O/ouU1M/oqoEVjwJ6T+HuEEnx6I1bF4Ai35nbvRO/rMdCiyEbUgCF11Lc7NZqaip3rSvr38LVj5jBig11cE5t8HFfzXH7lgEb//M3Dw9uMEk3+E3mxp7aHfTFXLta3DVq2a90qpieP0yKNxq2umnvwgDph9770N7TTfLnd+AfwRUl8AvPoKe44/Ftuz/zIRgY+6R2rlwOJkLRXQtHh7g22Lui3H3Q/r1sOQxqC0/vjbdexIMvwUyXoVB15iuji1XRYobbOaH+fhO0wPn64ehdBdc+YqZYve/s+DgPRAQafq/710Fnr4w5a9msY2Xx5sBT7evMn3Zv3oA1rxkrl1VbJbAkyQuuiCpgQvn0NwMFQchJKH1/ZWFMG8cHN5vkvN175oadWMdfPYbc8MVIHoA9JkCw2469iGwf60ZvTpohpkkbOXTcO6vzLeBH180C1Ff/CTUV0D+ZkBBt3OPb3OvKYOaQxCeYse/BOGupAYunJuHR9vJGyAw2kyz+/lv4cJHzZwvYAYeXf4CDL0BgmLN7I0nShhm+ruveNK8HnbTsTZxiyes+gdkfgqV+S3eL8YsVB2eYmr1Od9BcyP0uwwu/P3JKyc1NULxDnPjNWmk+aYgxFmSGrgQYLpGvnONaVOf9vSxOV20htUvQN4aMy9MXLqpiW9eYNZAbao3I1X7XWIW1Fg917Tp97/MDHCqLTffDgozTds+mO0pF5h2+T7TIKD1BYOFOEJuYgphazVlUFMKYSnH2sgrC+Hbv0LmZ2Ykq0+wuVEa0998AATFmZun2z4yXSCVB3QfbeaQ8Q0xM0E21YN3oOl54x8B1cVmlsnSXWaK4NTJEJt2crt8XQVsfNf07hlwJUT07Ny/D2E3ksCF6Eq0hoMbIesz0zxTlNX+Ob4hpkYP5oMg6RyITIWIXuZa6980A5+OiB9ikn1wnGny0c1wYAMcWGcGSnlYzBJ8Xr7meiFJ5gPCN8TcYPbyNx9S1cVmndaY/tB9zLFvDA21pknI4mlmt/QJkpu9diIJXIiurDzPtKF7+pl5Y+oqTA+Y6mLwCze1af9wU8PPXmyab/I3mVq8bjbNMv2nw7m3myS85QPTVz5/0/HvoywQ3c8kfq3Ne9ZXweEDJoaGqtaiO15kH2ioNse37Itv8TY3kFGgwPqHSeo+weYDIiTRlCU2zXwjUcqMCcj5zsQQ2s3cpwhOMOd4B5hrNjeah24232y8g8z9jepiM71DVZH5u/MNNt9eGqrNh09tublZHTfYfEiBudlctteU+8T8p5Qph3eAuY5PkInD0uJ2YVOD9d/K9+QPrKYGc92GanMDPSDSXOcsP9gkgQvhihrr4dAe8AszN3JP2l9nkltlgenJEzOg7bVOtTY1+LoKU+NuqDG18YAI8Aowc8nnrIDcn8z2iJ6m+Ug3mb70VcWm+Udrk2jNRc3r2jKT8MtyzTw6J/IJgbDuUJ5rEqw9+EeaBFtXfvrnegWYD9aGalNGMM1f3kFmJHFjndnX3NjKuf7m3+ayf0LK+WcUuvRCEcIVeXpD1CnWUvH0MbXekMT2r6WUtfkkBEJa2d/tHPM4W3UVULDNfDtoqjf3AGLTjnXLrCkzter6SvNoqDXfMCyegDKJsq7STFscEGV6FwVEmSRaW2b2eQeYDzXvQPMBd3CjeT9PP1PDD+tuymkKbv1p/bBpajj23kc+zOoOm1i9/M01PSympl1faW5ae/mbGrmXv/mA9PI3Cb+6xHxrqiww9zNsTBK4EKJz+QSd+sPAL9Q8bCUoxvTbd0Gy/pUQQjgpSeBCCOGkJIELIYSTkgQuhBBOShK4EEI4KUngQgjhpCSBCyGEk5IELoQQTqpTh9IrpYqAvWd4eiRQbMNwnIU7ltsdywzuWW53LDOcfrm7a62jTtzYqQn8bCilMlqbC8DVuWO53bHM4J7ldscyg+3KLU0oQgjhpCSBCyGEk3KmBD7P0QE4iDuW2x3LDO5ZbncsM9io3E7TBi6EEOJ4zlQDF0II0YIkcCGEcFJOkcCVUlOUUtuVUjuVUg84Oh57UEolKaWWKaUylVJblVJ3WbeHK6UWK6WyrT/DHB2rrSmlLEqp9Uqpz6yv3aHMoUqpBUqpLOu/+ShXL7dS6jfW3+0tSql3lFK+rlhmpdR8pVShUmpLi21tllMp9aA1t21XSk0+nffq8glcKWUBXgAuBvoD1yml+js2KrtoBH6rte4HnAv8ylrOB4AlWutUYIn1tau5C8hs8dodyvwc8JXWui8wGFN+ly23UioB+DUwXGs9ELAA1+KaZX4NmHLCtlbLaf0/fi0wwHrOXGvO65Aun8CBkcBOrfVurXU98C5wuYNjsjmt9UGt9Trr8wrMf+gETFlftx72OjDdIQHaiVIqEZgGvNJis6uXORgYC7wKoLWu11qX4eLlxizh6KeU8gT8gQO4YJm11iuA0hM2t1XOy4F3tdZ1Wus9wE5MzusQZ0jgCUBui9d51m0uSymVDAwBfgRitNYHwSR5oJWlx53as8B9QHOLba5e5h5AEfBva9PRK0qpAFy43Frr/cBTwD7gIFCutV6EC5f5BG2V86zymzMkcNXKNpft+6iUCgQ+AO7WWh92dDz2pJS6BCjUWq91dCydzBMYCryotR4CVOEaTQdtsrb5Xg6kAPFAgFJqpmOj6hLOKr85QwLPA5JavE7EfPVyOUopL0zyfktrvdC6uUApFWfdHwcUOio+OxgNXKaUysE0jU1QSr2Ja5cZzO90ntb6R+vrBZiE7srlvgjYo7Uu0lo3AAuB83DtMrfUVjnPKr85QwL/CUhVSqUopbwxDf6fODgmm1NKKUybaKbW+ukWuz4BZlmfzwI+7uzY7EVr/aDWOlFrnYz5d12qtZ6JC5cZQGudD+QqpfpYN10IbMO1y70POFcp5W/9Xb8Qc5/HlcvcUlvl/AS4Vinlo5RKAVKBNR2+qta6yz+AqcAOYBfwO0fHY6cyjsF8ddoEbLA+pgIRmLvW2daf4Y6O1U7lHwd8Zn3u8mUG0oEM67/3R0CYq5cbeAzIArYAbwA+rlhm4B1MO38DpoZ9y6nKCfzOmtu2AxefznvJUHohhHBSztCEIoQQohWSwIUQwklJAhdCCCclCVwIIZyUJHAhhHBSksCFEMJJSQIXQggn9f+xCznhAP3p6AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_forecast_error = pd.DataFrame(\n",
    "        columns=['h', 'mae', 'rmse', 'mape', 'descriptions'])\n",
    "history = model.fit(train_X, train_non_linear_y, epochs=100, batch_size=40, validation_data=(test_X, test_non_linear_y), verbose=1, shuffle=False)\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(603, 3)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_non_linear_y = model.predict(test_X)\n",
    "pred_non_linear_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_pred_non_linear_y = non_linear_y_scaler.inverse_transform(pred_non_linear_y.reshape(test_non_linear_y.shape))\n",
    "inverted_test_non_linear_y = non_linear_y_scaler.inverse_transform(test_non_linear_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_pred_non_linear_y=pd.DataFrame(inverted_pred_non_linear_y).apply(lambda x:x.sum(),axis=1).to_numpy().reshape(-1,1)\n",
    "inverted_test_non_linear_y=pd.DataFrame(inverted_test_non_linear_y).apply(lambda x:x.sum(),axis=1).to_numpy().reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'h': 1,\n",
       " 'mae': [0.7479202155749654],\n",
       " 'rmse': [0.995684177089333],\n",
       " 'mape': [0.013280179595296223],\n",
       " 'r2': [0.9863231562843955],\n",
       " 'descriptions': ''}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_linear_y=linear_y[train_size:].reshape(-1,1)\n",
    "inverted_pred_non_linear_y=inverted_pred_non_linear_y+test_linear_y\n",
    "inverted_test_non_linear_y=inverted_test_non_linear_y+test_linear_y\n",
    "evaluate_series(test_y, inverted_pred_non_linear_y, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'h': 1,\n",
       " 'mae': [0.0],\n",
       " 'rmse': [0.0],\n",
       " 'mape': [0.0],\n",
       " 'r2': [1.0],\n",
       " 'descriptions': ''}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_series(test_y, inverted_test_non_linear_y, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'h': 1,\n",
       " 'mae': [0.008526222247776626],\n",
       " 'rmse': [0.011350708813147892],\n",
       " 'mape': [0.025804959111471175],\n",
       " 'r2': [0.9863231562843955],\n",
       " 'descriptions': ''}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_scaler=MinMaxScaler().fit(train_y)\n",
    "normalized_pred_y=normalize_scaler.transform(inverted_pred_non_linear_y)\n",
    "normalized_inverted_test_y=normalize_scaler.transform(inverted_test_non_linear_y)\n",
    "normalized_test_y=normalize_scaler.transform(test_y)\n",
    "evaluate_series(normalized_test_y, normalized_pred_y, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'h': 1,\n",
       " 'mae': [0.0],\n",
       " 'rmse': [0.0],\n",
       " 'mape': [0.0],\n",
       " 'r2': [1.0],\n",
       " 'descriptions': ''}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_series(normalized_test_y, normalized_inverted_test_y, h)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8f3e05a59671f1eb5b3f5f0e003aaa5a39f5d3316373e39c3606e56079185283"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('OPP-env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
